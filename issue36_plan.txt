# Outline of functions needed to resolve MPoL issue #36
# https://github.com/MPoL-dev/MPoL/issues/36

################################################################################
# user-facing get_dirty_image routine
#
# Changes: now calls _grid_visibilities() interally rather than having the user call it in advance
#          now calls get_dirty_beam and returns image AND beam
################################################################################

def get_dirty_image(self, weighting="uniform", robust=None, taper_function=None, unit="Jy/beam"):
    """
    Calculate the dirty image.

    Args:
        weighting (string): The type of cell averaging to perform. Choices of ``"natural"``, ``"uniform"``, or ``"briggs"``, following CASA tclean. If ``"briggs"``, also specify a robust value.
        robust (float): If ``weighting='briggs'``, specify a robust value in the range [-2, 2]. ``robust=-2`` approxmately corresponds to uniform weighting and ``robust=2`` approximately corresponds to natural weighting.
        taper_function (function reference): a function assumed to be of the form :math:`f(u,v)` which calculates a prefactor in the range :math:`[0,1]` and premultiplies the visibility data. The function must assume that :math:`u` and :math:`v` will be supplied in units of :math:`\mathrm{k}\lambda`. By default no taper is applied.
        unit (string): what unit should the image be in. Default is ``"Jy/beam"``. If ``"Jy/arcsec^2"``, then the effective area of the dirty beam will be used to convert from ``"Jy/beam"`` to ``"Jy/arcsec^2"``.

    Returns: image,beam where
             image: (nchan, npix, npix) numpy array of the dirty image cube.
             beam: numpy image cube with a dirty beam (PSF) for each channel. The units are in Jy/{dirty beam}, i.e., the peak is normalized to 1.0.
    """

    # check unit input
    if unit not in ["Jy/beam", "Jy/arcsec^2"]:
        raise ValueError("Unknown unit", unit)

    # call _grid_visibilities
    # inputs for weighting will be checked inside _grid_visibilities
    self._grid_visibilities(weighting=weighting, robust=robust, taper_function=taper_function))

    # _grid_visibilities() will avg the loose visibilities according to specified weighting
    # then the imaging routine continues as it existed before:

    img = self._fliplr_cube(
        np.fft.fftshift(
            self.coords.npix ** 2
            * np.fft.ifft2(self.C[:, np.newaxis, np.newaxis] * self.vis_gridded),
            axes=(1, 2),
        )
    )  # Jy/beam

    # for units of Jy/arcsec^2, we could just leave out the C constant *if* we were doing
    # uniform weighting. The relationships get more complex for robust or natural weighting, however,
    # so it's safer to calculate the number of arcseconds^2 per beam
    if unit == "Jy/arcsec^2":
        beam_area_per_chan = self.get_dirty_beam_area()  # [arcsec^2]

        # convert image
        # (Jy/1 arcsec^2) = (Jy/ 1 beam) * (1 beam/ n arcsec^2)
        # beam_area_per_chan is the n of arcsec^2 per 1 beam

        img /= beam_area_per_chan[:, np.newaxis, np.newaxis]

    assert (
        np.max(img.imag) < 1e-10
    ), "Dirty image contained substantial imaginary values, check input visibilities, otherwise raise a github issue."

    self.img = img.real

    self.get_dirty_beam()

    return self.img,self.beam

################################################################################
# user-facing to_pytorch routine
#
# Changes: now calls _grid_visibilities() interally with UNIFORM weighting only
#          now calls _grid_weights() to get uncertainties
################################################################################

def to_pytorch_dataset(self):
    """
    Export gridded visibilities to a PyTorch dataset object.

    Returns:
        :class:`~mpol.datasets.GriddedDataset` with gridded visibilities.
    """

    # grid visibilites (uniform weighting hard-coded in here) and weights
    self._grid_visibilities(weighting="unform")
    self._grid_weights()

    # This should be an obsolete check now but I'll leave it here for now
    assert (
        self.weight_gridded is not None
    ), "To export with uncertainties, first grid visibilities with weighting='uniform', no tapering function, and robust=None. Otherwise, data weights are not defined."

    return GriddedDataset(
        coords=self.coords,
        nchan=self.nchan,
        vis_gridded=self.vis_gridded,
        weight_gridded=self.weight_gridded,
        mask=self.mask,
    )

################################################################################
# internal-only _grid_visibilities()
#
# Changes: removed lines at the end of the original grid_visibilities which set weight_gridded
################################################################################
def _grid_visibilities(self, weighting="uniform", robust=None, taper_function=None):
    r"""
    Grid the loose data visibilities to the Fourier grid in preparation for imaging.

    Args:
        weighting (string): The type of cell averaging to perform. Choices of ``"natural"``, ``"uniform"``, or ``"briggs"``, following CASA tclean. If ``"briggs"``, also specify a robust value.
        robust (float): If ``weighting='briggs'``, specify a robust value in the range [-2, 2]. ``robust=-2`` approxmately corresponds to uniform weighting and ``robust=2`` approximately corresponds to natural weighting.
        taper_function (function reference): a function assumed to be of the form :math:`f(u,v)` which calculates a prefactor in the range :math:`[0,1]` and premultiplies the visibility data. The function must assume that :math:`u` and :math:`v` will be supplied in units of :math:`\mathrm{k}\lambda`. By default no taper is applied.
    """

    if taper_function is None:
        tapering_weight = np.ones_like(self.weight)
    else:
        tapering_weight = taper_function(self.uu, self.vv)

    # create the cells as edges around the existing points
    # note that at this stage, the UV grid is strictly increasing
    # when in fact, later on, we'll need to fftshift for the FFT
    cell_weight = self._histogram_cube(self.weight)

    # boolean index for cells that *contain* visibilities
    mask = cell_weight > 0.0

    # calculate the density weights
    # the density weights have the same shape as the re, im samples.
    if weighting == "natural":
        density_weight = np.ones_like(self.weight)
    elif weighting == "uniform":
        # cell_weight is (nchan, ncell_v, ncell_u)
        # self.index_v, self.index_u are (nchan, nvis)
        # we want density_weights to be (nchan, nvis)
        density_weight = 1 / np.array(
            [
                cell_weight[i][self.index_v[i], self.index_u[i]]
                for i in range(self.nchan)
            ]
        )

    elif weighting == "briggs":
        if robust is None:
            raise ValueError(
                "If 'briggs' weighting, a robust value must be specified between [-2, 2]."
            )
        assert (robust >= -2) and (
            robust <= 2
        ), "robust parameter must be in the range [-2, 2]"

        # implement robust weighting using the definition used in CASA
        # https://casa.nrao.edu/casadocs-devel/stable/imaging/synthesis-imaging/data-weighting

        # calculate the robust parameter f^2 for each channel
        f_sq = ((5 * 10 ** (-robust)) ** 2) / (
            np.sum(cell_weight ** 2, axis=(1, 2)) / np.sum(self.weight, axis=1)
        )

        # the robust weight corresponding to the cell
        cell_robust_weight = 1 / (1 + cell_weight * f_sq[:, np.newaxis, np.newaxis])

        # zero out cells that have no visibilities
        # to prevent normalization error in next step
        cell_robust_weight[~mask] = 0

        # now assign the cell robust weight to each visibility within that cell
        density_weight = np.array(
            [
                cell_robust_weight[i][self.index_v[i], self.index_u[i]]
                for i in range(self.nchan)
            ]
        )
    else:
        raise ValueError(
            "weighting must be specified as one of 'natural', 'uniform', or 'briggs'"
        )

    # the factor of 2 in the denominator is needed because
    # we are approximating the Eqn 3.8 of Briggs' thesis
    # we need to sum over the Hermitian quantities in the
    # normalization constant.
    self.C = 1 / np.sum(tapering_weight * density_weight * self.weight, axis=1)

    # grid the reals and imaginaries separately
    # outputs from _histogram_cube are *not* pre-packed
    data_re_gridded = self._histogram_cube(
        self.data_re * tapering_weight * density_weight * self.weight
    )

    data_im_gridded = self._histogram_cube(
        self.data_im * tapering_weight * density_weight * self.weight
    )

    # the beam is the response to a point source, which is data_re = constant, data_im = 0
    # so we save time and only calculate the reals, because gridded_beam_im = 0
    re_gridded_beam = self._histogram_cube(
        tapering_weight * density_weight * self.weight
    )

    # store the pre-packed FFT products for access by outside routines
    self.mask = np.fft.fftshift(mask)
    self.data_re_gridded = np.fft.fftshift(data_re_gridded, axes=(1, 2))
    self.data_im_gridded = np.fft.fftshift(data_im_gridded, axes=(1, 2))
    self.vis_gridded = self.data_re_gridded + self.data_im_gridded * 1.0j
    self.re_gridded_beam = np.fft.fftshift(re_gridded_beam, axes=(1, 2))

################################################################################
# new, internal-only _grid_weights()
#
# I removed the "weighting" argument since we'd only want uniform weighting here
################################################################################
def _grid_weights(self):
    r"""
    Grid the loose data visibilities to the Fourier grid in preparation for imaging.
    """

    # create the cells as edges around the existing points
    # note that at this stage, the UV grid is strictly increasing
    # when in fact, later on, we'll need to fftshift for the FFT
    cell_weight = self._histogram_cube(self.weight)

    # instantiate uncertainties for each averaged visibility.
    self.weight_gridded = np.fft.fftshift(cell_weight, axes=(1, 2))
