{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f029f89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-13T20:20:33.433239Z",
     "iopub.status.busy": "2023-03-13T20:20:33.432532Z",
     "iopub.status.idle": "2023-03-13T20:20:33.817662Z",
     "shell.execute_reply": "2023-03-13T20:20:33.816951Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run notebook_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d43e19",
   "metadata": {},
   "source": [
    "# Using MPoL for Parametric Inference with Pyro\n",
    "\n",
    "In all of the tutorials thus far, we have used MPoL to optimize non-parametric image plane models, i.e., collections of pixels. However, there may be instances where the astrophysical source morphology is simple enough at the resolution of the data such that an investigator might wish to fit a parametric model to the data. In the protoplanetary disk field, there is a long history of parametric model fits to data. The simplest example of this would be an elliptcial Gaussian fit through CASA's [uvmodelfit](https://casadocs.readthedocs.io/en/stable/api/tt/casatasks.manipulation.uvmodelfit.html), while a more complex example might be the [Galario](https://mtazzari.github.io/galario/) package. While non-paramtetric models tend to get all of the attention in this era of Big Data, well-constructed parametric models can still prove useful thanks to their interpretability and role in Bayesian inference.\n",
    "\n",
    "In this tutorial, we will explore how we can use MPoL with a probabilistic programming language called [Pyro](https://pyro.ai/) to perform parametric model fitting with a continuum protoplanetary disk dataset and derive posterior probability distributions of the model parameters. One major advantage of using MPoL + Pyro to do parametric model fitting compared to existing packages is that posterior gradient information is naturally provided by PyTorch's autodifferentiation capabilities. This, coupled with the industry-grade inference algorithms provided by Pyro, makes it computationally efficient to explore posterior probability distributions with dozens or even hundreds of parameters--something that would be impractical using classical MCMC algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539580e1",
   "metadata": {},
   "source": [
    "## MPoL as a differentiable FFT link\n",
    "\n",
    "Before we discuss the specifics of the parametric disk model, let's take a moment to do a high-level review of what a typical MPoL model might look like. \n",
    "\n",
    "### Non-parametric models \n",
    "Let's start by considering the architecture of the simplest possible skeleton non-parametric RML model\n",
    "\n",
    "\n",
    "```{mermaid} ../_static/mmd/src/ImageCube.mmd\n",
    "```\n",
    "\n",
    "When we say that a model is non-parametric we generally mean that the number of parameters of the model is vast (potentially infinite) and can grow to encapsulate more detail if needed. A classic example is something like a spline or a Gaussian process, but in our case we are using a large number of discrete pixel fluxes to represent an image.\n",
    "\n",
    "We can see the definition of the \"non-parametric\" image parameters in the Pytorch layer\n",
    "\n",
    "```\n",
    "self.cube = nn.Parameter(\n",
    "    torch.full(\n",
    "        (self.nchan, self.coords.npix, self.coords.npix),\n",
    "        fill_value=0.0,\n",
    "        requires_grad=True,\n",
    "        dtype=torch.double,\n",
    "    )\n",
    ")\n",
    "```\n",
    "The `nn.Parameter` call tells Pytorch that the `cube` tensor should be varied during optimization of the model. The `cube` tensor is effectively the set of parameters for the \"non-parametric\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb0847",
   "metadata": {},
   "source": [
    "We can consider the architecture of the {class}`mpol.precomposed.SimpleNet` as a more practical extension \n",
    "\n",
    "\n",
    "```{mermaid} ../_static/mmd/src/SimpleNet.mmd\n",
    "```\n",
    "\n",
    "The functionality of the {class}`mpol.precomposed.SimpleNet` is similar to the skeleton model, but we've shifted the base parameterization from the {class}`mpol.images.ImageCube` to the {class}`mpol.images.BaseCube` (so that pixel flux values are non-negative) and we've included a small convolution kernel (through {class}`mpol.images.HannConvCube`) so that high-spatial-frequency noise is supressed. In this framework, the `nn.Parameter`s are instantiated on the {class}`~mpol.images.BaseCube` and the {class}`~mpol.images.ImageCube` becomes a pass-through layer.\n",
    "\n",
    "In both of these cases, the key functionality provided by the MPoL package is the {class}`mpol.fourier.FourierCube` layer that translates a model image into the visibility plane. From the perspective of the {class}`~mpol.fourier.FourierCube`, it doesn't care how the model image was produced, it will happily translate image pixels into visibility values using the FFT.\n",
    "\n",
    "### Parametric models\n",
    "\n",
    "By contrast to a non-parametric model, a *parametric* model is one that has a (finite) set of parameters (generally decoupled from the size of the data) and can be easily used to make future predictions of the data, usually in a functional form. For example, a cubic function and its coefficients would be considered a parametric model. For a radio astronomy example, you can think of the {class}`~mpol.images.BaseCube` and {class}`mpol.images.HannConvCube` layers as being replaced by a parametric model. This parametric model would specify pixel brightness as a function of position based upon model parameters, and would feed directly into the {class}`~mpol.images.ImageCube` pass-through layer.\n",
    "\n",
    "```{mermaid} ../_static/mmd/src/Parametric.mmd\n",
    "```\n",
    "\n",
    "Before ALMA, it was common in the protoplanetary disk field to fit parametric models (e.g., elliptical Gaussians, one or two axisymmetric rings, etc...) to interferometric observations to derive source properties like size and inclination. The spatial resolution afforded by the ALMA long-baseline campaign rendered many of these simple parametric models inadequate. Suddenly, rich substructure in the forms of rings, gaps, and spirals was visible in dust continuum images and, except for a few exceptions we'll discuss in a second, these morphologies were too complex to neatly capture with simple model parameterizations.\n",
    "\n",
    "This spurred a major shift from parametric, visibility-based analyses to image-based analysis (including our own MPoL efforts). For axisymmetric sources, visibility-based analysis is still viable thanks to the development of novel non-parametric 1D models like [frank](https://discsim.github.io/frank/), which are capable of super-resolution compared to image-based methods like CLEAN.\n",
    "\n",
    "In our opinion, the two (linked) reasons that parametric model fitting has fallen out of favor in the protoplanetary disk field are \n",
    "\n",
    "1. ALMA data are sufficiently high quality that many model parameters are required to accurately describe disk emission\n",
    "2. standard sampling algorithms used for Bayesian inference do not perform well in high dimensional parameter spaces\n",
    "\n",
    "As we hinted at, the MPoL + Pyro + PyTorch framework will help us out on point #2, such that we might be able to explore more detailed models with larger numbers of parameters.\n",
    "\n",
    "This point of this tutorial isn't to say that actually everyone should switch back to using parametric models. But, rather that, with the industry-grade machinery of probalistic programming languages and autodifferentiation, there may be many use-cases where parametric models are still helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2d36f",
   "metadata": {},
   "source": [
    "## DSHARP AS 209 continuum dataset\n",
    "\n",
    "summary of DSHARP dataset, dirty images, review of Guzman et al. 2018 approach\n",
    "\n",
    "## Introduction to Probabilistic Programming Languages and Pyro\n",
    "\n",
    "describe Pyro PPL and highlight a few examples using static code of PyroSample.\n",
    "\n",
    "Bayesian workflow by Gelman et al.\n",
    "\n",
    "## Building a parametric disk model \n",
    "\n",
    "build and heavily comment the disk model, including MPoL geometry routines, deterministic statements\n",
    "\n",
    "## Parameter inference with Stochastic Variational Inference (SVI)\n",
    "run SVI inference loop on GPU\n",
    "analyze samples\n",
    "explore MultiNormal fits to see if posterior changes\n",
    "\n",
    "## Parameter inference with MCMC and Hamiltonian Monte Carlo\n",
    "run HMC loop on GPU and analyze samples\n",
    "show scatter in 1D profile as draws or movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce75df46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
