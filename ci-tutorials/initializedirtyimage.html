

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Initializing with the Dirty Image &mdash; MPoL 0.1.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="https://buttons.github.io/buttons.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
  <link rel="stylesheet" href="../_static/bullets.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/faculty.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans|Roboto:400,700|Roboto+Mono:400,700&display=swap" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="HD143006 Tutorial Part 1" href="../large-tutorials/HD143006_part_1.html" />
    <link rel="prev" title="GPU Acceleration" href="gpu_setup.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

  
    <a class="heading heading-extra-margin" href="../index.html">
      <div class="logo-box logo-box-large">
        <img class="logo" src="../_static/logo.png"/>
      </div>
      
        <span class="icon icon-home"> MPoL</span>
      
    </a>
  

  
    
    
      <div class="version">0.1.1</div>
    
  

  
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rml_intro.html">Introduction to Regularized Maximum Likelihood Imaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">MPoL Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../units-and-conventions.html">Units and Conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer-documentation.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="PyTorch.html">Introduction to PyTorch: Tensors and Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="gridder.html">Gridding and diagnostic images</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">Optimization Loop</a></li>
<li class="toctree-l1"><a class="reference internal" href="crossvalidation.html">Cross validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu_setup.html">GPU Acceleration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Initializing with the Dirty Image</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#image-setup">Image Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-and-optimization-setup">Model and Optimization Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loss-function">Loss Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-loop">Training Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#saving-the-model">Saving the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-the-model">Loading the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../large-tutorials/HD143006_part_1.html">HD143006 Tutorial Part 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../large-tutorials/HD143006_part_2.html">HD143006 Tutorial Part 2</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MPoL</a>
        
      </nav>


      <div class="wy-nav-content">

  

  
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
  <li class="breadcrumb"><a href="../index.html">MPoL</a> &raquo;</li>
    
  <li class="breadcrumb">Initializing with the Dirty Image</li>

    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/ci-tutorials/initializedirtyimage.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%run notebook_setup
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/work/MPoL/MPoL/docs/ci-tutorials/notebook_setup.py:7: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).
  get_ipython().magic(&#39;config InlineBackend.figure_format = &quot;retina&quot;&#39;)
</pre></div>
</div>
</div>
</details>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="initializing-with-the-dirty-image">
<h1>Initializing with the Dirty Image<a class="headerlink" href="#initializing-with-the-dirty-image" title="Permalink to this heading">¶</a></h1>
<p>The core computational process required to synthesize an image with a regularized maximum likelihood (RML) algorithm is an optimization loop (as seen in the <a class="reference internal" href="optimization.html"><span class="doc std std-doc">Optimization Tutorial</span></a>) powered by gradient descent. In theory, we could start this optimization process from a random or neutral starting point (e.g., a blank image), and with enough iterations of the optimization algorithm, we will eventually converge to the “optimal” image (assuming there is a single, global maximum). If we could choose a “better” starting point, however, we’ll need fewer iterations of our optimization loop to converge to the optimal image. A reasonable starting point is the dirty image, since it is already a maximum likelihood fit the data (though of course, it is unregularized).</p>
<p>The problem with the dirty image is that it usually contains negative flux pixels and we’d like to impose the (rather strong) prior that the astrophysical source must have positive intensity values (i.e., no negative flux values are permitted). Image positivity is enforced by default through the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a> parameterization.</p>
<p>So the question is how can we initialize the RML image model to the dirty image if we can’t represent negative flux pixels?</p>
<p>This tutorial will demonstrate one initialization solution, which is to create a loss function corresponding to the mean squared error between the RML model image pixel fluxes and the dirty image pixel fluxes and then optimize the RML model. We will also cover how to save and load the starting point configuration. After saving and loading it, it can be then optimized against the visibility data to complete it (though this will not be done in this tutorial). We will use the dataset of the ALMA logo first used in the Gridding and Diagnostic Images tutorial.</p>
<section id="image-setup">
<h2>Image Setup<a class="headerlink" href="#image-setup" title="Permalink to this heading">¶</a></h2>
<p>Here we will set up the ALMA Logo image dataset and display it. Consult the <a class="reference internal" href="gridder.html"><span class="doc std std-doc">Gridding and Diagnostic Images Tutorial</span></a> for reference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
import numpy as np
import torch
from astropy.utils.data import download_file
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from mpol import coordinates, gridding, losses, precomposed, utils
</pre></div>
</div>
</div>
</div>
<p>When saving and loading a model, it is important to make sure that <code class="docutils literal notranslate"><span class="pre">cell_size</span></code>, <code class="docutils literal notranslate"><span class="pre">nchan</span></code>, and <code class="docutils literal notranslate"><span class="pre">npix</span></code> remain the same. More info on coordinates can be found in <a class="reference internal" href="../api.html#mpol.coordinates.GridCoords" title="mpol.coordinates.GridCoords"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.coordinates.GridCoords</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># load the mock dataset of the ALMA logo
fname = download_file(
    &quot;https://zenodo.org/record/4930016/files/logo_cube.noise.npz&quot;,
    cache=True,
    show_progress=True,
    pkgname=&quot;mpol&quot;,
)

# this is a multi-channel dataset... but for demonstration purposes we&#39;ll use
# only the central, single channel
chan = 4
d = np.load(fname)
uu = d[&quot;uu&quot;][chan]
vv = d[&quot;vv&quot;][chan]
weight = d[&quot;weight&quot;][chan]
data = d[&quot;data&quot;][chan]
data_re = data.real
data_im = data.imag

# define the image dimensions, making sure they are big enough to fit all
# of the expected emission
coords = coordinates.GridCoords(
    cell_size=0.03, npix=180
)  # Smaller cell size and larger npix value can greatly increase run time
gridder = gridding.Gridder(
    coords=coords, uu=uu, vv=vv, weight=weight, data_re=data_re, data_im=data_im
)

# export to PyTorch dataset
dset = gridder.to_pytorch_dataset()
</pre></div>
</div>
</div>
</div>
<p>Now let’s calculate the dirty image. Here we’re using Briggs weighting with a robust value of 1.0, but you can use whichever weighting scheme you think looks best for your dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Calculate the dirty image
img, beam = gridder.get_dirty_image(weighting=&quot;briggs&quot;, robust=1.0, unit=&quot;Jy/beam&quot;)
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize this dirty image. Here we’re using an aggressive colormap to highlight the many negative flux pixels contained in this image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.set_cmap(
    &quot;Spectral&quot;
)  # using Matplotlib diverging colormap to accentuate negative values
kw = {&quot;origin&quot;: &quot;lower&quot;, &quot;extent&quot;: gridder.coords.img_ext}
fig, ax = plt.subplots(ncols=1)
snp = ax.imshow(np.squeeze(img), **kw)
ax.set_title(&quot;image&quot;)
ax.set_xlabel(r&quot;$\Delta \alpha \cos \delta$ [${}^{\prime\prime}$]&quot;)
ax.set_ylabel(r&quot;$\Delta \delta$ [${}^{\prime\prime}$]&quot;)
plt.colorbar(snp)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fe9877e5df0&gt;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 480x480 with 0 Axes&gt;
</pre></div>
</div>
<img alt="../_images/9d91b00325defe5e561a2e014b4a3e31f4b5cdc859ff1beb2f115b2d15ee56d7.png" src="../_images/9d91b00325defe5e561a2e014b4a3e31f4b5cdc859ff1beb2f115b2d15ee56d7.png" />
</div>
</div>
<p>We can see that there are a number of pixels with negative flux values</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.sum(img &lt; 0)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>18099
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-and-optimization-setup">
<h2>Model and Optimization Setup<a class="headerlink" href="#model-and-optimization-setup" title="Permalink to this heading">¶</a></h2>
<p>Here we set the optimizer and the image model (RML). If this is unfamiliar please reference the <a class="reference internal" href="optimization.html"><span class="doc std std-doc">Optimization tutorial</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dirty_image = torch.tensor(img.copy())  # turns it into a pytorch tensor
rml = precomposed.SimpleNet(coords=coords, nchan=dset.nchan)
optimizer = torch.optim.SGD(
    rml.parameters(), lr=1000.0
)  # multiple different possiple optimizers
</pre></div>
</div>
</div>
</div>
</section>
<section id="loss-function">
<h2>Loss Function<a class="headerlink" href="#loss-function" title="Permalink to this heading">¶</a></h2>
<p>The loss function (<a class="reference internal" href="../api.html#module-mpol.losses" title="mpol.losses"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mpol.losses</span></code></a>) that will be used to optimize the initial part of the image is the pixel-to-pixel L2 norm (also known as the Euclidian Norm). It calculates the loss based off of the image-plane distance between the dirty image and the state of the ImageCube in order to make the state of the ImageCube closer to the dirty image. <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html">Pytorch provides a loss function for mean squared error</a> which is the squared L2 norm so we will be using the square root of that.</p>
</section>
<section id="training-loop">
<h2>Training Loop<a class="headerlink" href="#training-loop" title="Permalink to this heading">¶</a></h2>
<p>Now we train using this loss function to optimize our parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>loss_tracker = []
for iteration in range(50):

    optimizer.zero_grad()

    rml.forward()

    sky_cube = rml.icube.sky_cube

    lossfunc = torch.nn.MSELoss(
        reduction=&quot;sum&quot;
    )  # the MSELoss calculates mean squared error (squared L2 norm), so we take the sqrt of it
    loss = (lossfunc(sky_cube, dirty_image)) ** 0.5

    loss_tracker.append(loss.item())
    loss.backward()
    optimizer.step()
#
# We see that the optimization has completed successfully
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, ax = plt.subplots(nrows=1)
ax.plot(loss_tracker)
ax.set_xlabel(&quot;iteration&quot;)
ax.set_ylabel(&quot;loss&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;loss&#39;)
</pre></div>
</div>
<img alt="../_images/b682d8330f5b9c5184a8d7b97721f04b3de7e9269f8aef5a8661b9de1dcb90e3.png" src="../_images/b682d8330f5b9c5184a8d7b97721f04b3de7e9269f8aef5a8661b9de1dcb90e3.png" />
</div>
</div>
<p>Let’s visualize the resulting image cube representation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>img = np.squeeze(rml.icube.sky_cube.detach().numpy())
fig, ax = plt.subplots(nrows=1)
im = ax.imshow(
    img, origin=&quot;lower&quot;, interpolation=&quot;none&quot;, extent=rml.icube.coords.img_ext
)
plt.colorbar(im)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fe984580490&gt;
</pre></div>
</div>
<img alt="../_images/24880f1d67d70f5a123906b4b9b365d29e1ec075ddeebd2686c4cce6206c6b3a.png" src="../_images/24880f1d67d70f5a123906b4b9b365d29e1ec075ddeebd2686c4cce6206c6b3a.png" />
</div>
</div>
<p>We see that the cube resembles the dirty image, but it contains no pixels with negative flux values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.sum(img &lt; 0)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<p>We can also plot this with a normal colormap,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, ax = plt.subplots(nrows=1)
im = ax.imshow(
    img,
    origin=&quot;lower&quot;,
    interpolation=&quot;none&quot;,
    extent=rml.icube.coords.img_ext,
    cmap=&quot;viridis&quot;,
)
plt.colorbar(im)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fe9844ac4c0&gt;
</pre></div>
</div>
<img alt="../_images/8367f01714959fb1788355d69007a377db03916c60c048df985166058a6f4956.png" src="../_images/8367f01714959fb1788355d69007a377db03916c60c048df985166058a6f4956.png" />
</div>
</div>
</section>
<section id="saving-the-model">
<h2>Saving the Model<a class="headerlink" href="#saving-the-model" title="Permalink to this heading">¶</a></h2>
<p>Now that we’re happy that the state of the image cube model is approximately initialized to the dirty image, we can save it to disk so that we may easily reuse it in future optimization loops. This is as simple as</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>torch.save(rml.state_dict(), &quot;dirty_image_model.pt&quot;)
</pre></div>
</div>
</div>
</div>
<p>For more information on saving and loading models in PyTorch, please consult the official <a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">documentation</a>.</p>
</section>
<section id="loading-the-model">
<h2>Loading the Model<a class="headerlink" href="#loading-the-model" title="Permalink to this heading">¶</a></h2>
<p>Now let’s assume we’re about to start an optimization loop in a new file, and we’ve just created a new model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rml = precomposed.SimpleNet(coords=coords)
rml.state_dict()  # the now uninitialized parameters of the model (the ones we started with)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;bcube.base_cube&#39;,
              tensor([[[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       ...,
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]]],
                     dtype=torch.float64)),
             (&#39;conv_layer.m.weight&#39;,
              tensor([[[[0.0625, 0.1250, 0.0625],
                        [0.1250, 0.2500, 0.1250],
                        [0.0625, 0.1250, 0.0625]]]], dtype=torch.float64)),
             (&#39;conv_layer.m.bias&#39;, tensor([0.], dtype=torch.float64))])
</pre></div>
</div>
</div>
</div>
<p>Here you can clearly see the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> is in its original state, before the training loop changed the paramters through the optimization function. Loading our saved dirty image state into the model is as simple as</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rml.load_state_dict(torch.load(&quot;dirty_image_model.pt&quot;))
rml.state_dict()  # the reloaded parameters of the model
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;bcube.base_cube&#39;,
              tensor([[[-5.0804, -4.8556, -5.1265,  ..., -5.4252, -5.4998, -5.3646],
                       [-5.4508, -5.2860, -5.4591,  ..., -5.6400, -5.7612, -5.6770],
                       [-5.6921, -5.5713, -5.6573,  ..., -5.8351, -5.9434, -5.8712],
                       ...,
                       [-4.1607, -3.8701, -3.9250,  ..., -4.8574, -4.7145, -4.4097],
                       [-4.3247, -3.9789, -4.1579,  ..., -4.9576, -4.8731, -4.6139],
                       [-4.6532, -4.3457, -4.6481,  ..., -5.1825, -5.1763, -4.9727]]],
                     dtype=torch.float64)),
             (&#39;conv_layer.m.weight&#39;,
              tensor([[[[0.0625, 0.1250, 0.0625],
                        [0.1250, 0.2500, 0.1250],
                        [0.0625, 0.1250, 0.0625]]]], dtype=torch.float64)),
             (&#39;conv_layer.m.bias&#39;, tensor([0.], dtype=torch.float64))])
</pre></div>
</div>
</div>
</div>
<p>Now you can proceed with optimizing the model against the visibility data as before, but you should hopefully have a much better starting point.</p>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">¶</a></h2>
<p>This tutorial shows how to work towards a better starting point for RML optimization by starting from the dirty image. We should note, however, that RML optimization does not <em>need</em> to start from the dirty image—it’s entirely possible to start from a blank image or even a random image. In that sense, the RML imaging process could be described as an optimization process compared to a <a class="reference external" href="https://casa.nrao.edu/casadocs/casa-6.1.0/imaging/synthesis-imaging/deconvolution-algorithms#:~:text=Deconvolution%20refers%20to%20the%20process,spread%2Dfunction%20of%20the%20instrument">deconvolution process</a> like <a class="reference external" href="https://casa.nrao.edu/docs/taskref/tclean-task.html">CASA tclean</a>.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../large-tutorials/HD143006_part_1.html" class="btn btn-neutral float-right" title="HD143006 Tutorial Part 1" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="gpu_setup.html" class="btn btn-neutral float-left" title="GPU Acceleration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-21, Ian Czekala

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>


      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-5472810-8', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>