

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Optimization Loop &mdash; MPoL 0.1.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://buttons.github.io/buttons.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/bullets.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/faculty.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans|Roboto:400,700|Roboto+Mono:400,700&display=swap" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cross validation" href="crossvalidation.html" />
    <link rel="prev" title="Gridding and diagnostic images" href="gridder.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

  
    <a class="heading heading-extra-margin" href="../index.html">
      <div class="logo-box logo-box-large">
        <img class="logo" src="../_static/logo.png"/>
      </div>
      
        <span class="icon icon-home"> MPoL</span>
      
    </a>
  

  
    
    
      <div class="version">0.1.1</div>
    
  

  
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rml_intro.html">Introduction to Regularized Maximum Likelihood Imaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">MPoL Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../units-and-conventions.html">Units and Conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer-documentation.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="PyTorch.html">Introduction to PyTorch: Tensors and Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="gridder.html">Gridding and diagnostic images</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Optimization Loop</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Gridding-recap">Gridding recap</a></li>
<li class="toctree-l2"><a class="reference internal" href="#The-PyTorch-dataset">The PyTorch dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Building-an-image-model">Building an image model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Breaking-down-the-training-loop">Breaking down the training loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Loss-functions">Loss functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Gradient-descent">Gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Iterating-the-training-Loop">Iterating the training Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Visualizing-output">Visualizing output</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Wrapup">Wrapup</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="crossvalidation.html">Cross validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu_setup.html">GPU Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializedirtyimage.html">Initializing with the Dirty Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../large-tutorials/HD143006_part_1.html">HD143006 Tutorial Part 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../large-tutorials/HD143006_part_2.html">HD143006 Tutorial Part 2</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MPoL</a>
        
      </nav>


      <div class="wy-nav-content">

  

  
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
  <li class="breadcrumb"><a href="../index.html">MPoL</a> &raquo;</li>
    
  <li class="breadcrumb">Optimization Loop</li>

    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/ci-tutorials/optimization.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Optimization-Loop">
<h1>Optimization Loop<a class="headerlink" href="#Optimization-Loop" title="Permalink to this heading">¶</a></h1>
<p>In this tutorial, we’ll construct an optimization loop demonstrating how we can use MPoL to synthesize a basic image. We’ll continue with the dataset described in the <a class="reference external" href="gridder.html">Gridding and Diagnostic Images</a> tutorial.</p>
<section id="Gridding-recap">
<h2>Gridding recap<a class="headerlink" href="#Gridding-recap" title="Permalink to this heading">¶</a></h2>
<p>Let’s set up the gridder and coordinates as before</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">astropy.utils.data</span> <span class="kn">import</span> <span class="n">download_file</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">SVG</span><span class="p">,</span> <span class="n">display</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpol</span> <span class="kn">import</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">gridding</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">precomposed</span><span class="p">,</span> <span class="n">utils</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the mock dataset of the ALMA logo</span>
<span class="n">fname</span> <span class="o">=</span> <span class="n">download_file</span><span class="p">(</span>
    <span class="s2">&quot;https://zenodo.org/record/4930016/files/logo_cube.noise.npz&quot;</span><span class="p">,</span>
    <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pkgname</span><span class="o">=</span><span class="s2">&quot;mpol&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># this is a multi-channel dataset... for demonstration purposes we&#39;ll use</span>
<span class="c1"># only the central, single channel</span>
<span class="n">chan</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="n">uu</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;uu&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">vv</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;vv&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">data_re</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data_im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the image dimensions, as in the previous tutorial</span>
<span class="n">coords</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">GridCoords</span><span class="p">(</span><span class="n">cell_size</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">npix</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<span class="n">gridder</span> <span class="o">=</span> <span class="n">gridding</span><span class="o">.</span><span class="n">Gridder</span><span class="p">(</span>
    <span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span>
    <span class="n">uu</span><span class="o">=</span><span class="n">uu</span><span class="p">,</span>
    <span class="n">vv</span><span class="o">=</span><span class="n">vv</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
    <span class="n">data_re</span><span class="o">=</span><span class="n">data_re</span><span class="p">,</span>
    <span class="n">data_im</span><span class="o">=</span><span class="n">data_im</span><span class="p">,</span>
<span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="The-PyTorch-dataset">
<h2>The PyTorch dataset<a class="headerlink" href="#The-PyTorch-dataset" title="Permalink to this heading">¶</a></h2>
<p>Now we will export the visibilities to a PyTorch dataset to use in the imaging loop. The <code class="docutils literal notranslate"><span class="pre">to_pytorch_dataset</span></code> routine grids the visibilities with “uniform” weighting (in order to propagate the uncertainties needed for RML correctly) and exports the visibilities to cube-like PyTorch tensors. To keep things simple in this tutorial, we are only using a single channel. But you could just as easily export a multi-channel dataset. Note that the <code class="docutils literal notranslate"><span class="pre">to_pytorch_dataset</span></code> routine automatically checks the
visibility scatter and raises a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code> if the empirically-estimated scatter exceeds that expected from the provided dataset weights. For more information, see the end of the <a class="reference external" href="gridder.html">Gridding and Diagnostic Images Tutorial</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dset</span> <span class="o">=</span> <span class="n">gridder</span><span class="o">.</span><span class="n">to_pytorch_dataset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;this dataset has </span><span class="si">{:}</span><span class="s2"> channel&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">nchan</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
this dataset has 1 channel
</pre></div></div>
</div>
</section>
<section id="Building-an-image-model">
<h2>Building an image model<a class="headerlink" href="#Building-an-image-model" title="Permalink to this heading">¶</a></h2>
<p>MPoL provides “modules” to build and optimize complex imaging workflows, not dissimilar to how a deep neural network might be constructed. We’ve bundled the most common modules for imaging together in a <a class="reference external" href="../api.html#mpol.precomposed.SimpleNet">SimpleNet</a> meta-module, which we’ll use here.</p>
<p>This diagram shows how the primitive modules, like <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a>, <a class="reference external" href="../api.html#mpol.images.ImageCube">ImageCube</a>, etc… are connected together to form <a class="reference external" href="../api.html#mpol.precomposed.SimpleNet">SimpleNet</a>. In this workflow, the pixel values of the <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a> are the core model parameters representing the image. More information about all of these components is available in the <a class="reference external" href="../api.html">API documentation</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">SVG</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;../_static/mmd/build/SimpleNet.svg&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/ci-tutorials_optimization_11_0.svg" src="../_images/ci-tutorials_optimization_11_0.svg" /></div>
</div>
<p>It isn’t necessary to construct a meta-module to do RML imaging with MPoL, though it often helps organize your code. If we so desired, we could connect the individual modules together ourselves ourselves <a class="reference external" href="../_modules/mpol/precomposed.html#SimpleNet">(following the SimpleNet source code as an example)</a> and swap in/out modules as we saw fit.</p>
<p>We then initialize SimpleNet with the relevant information</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span> <span class="o">=</span> <span class="n">precomposed</span><span class="o">.</span><span class="n">SimpleNet</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span> <span class="n">nchan</span><span class="o">=</span><span class="n">dset</span><span class="o">.</span><span class="n">nchan</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Breaking-down-the-training-loop">
<h2>Breaking down the training loop<a class="headerlink" href="#Breaking-down-the-training-loop" title="Permalink to this heading">¶</a></h2>
<p>Our goal for the rest of the tutorial is to set up a loop that will</p>
<ol class="arabic simple">
<li><p>evaluate the current model against a loss function</p></li>
<li><p>calculate the gradients of the loss w.r.t. the model</p></li>
<li><p>advance the model parameters in the direction to minimize the loss function</p></li>
</ol>
<p>We’ll start by creating the optimizer</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">8000.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The role of the optimizer is to advance the parameters (in this case, the pixel values of the <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a>) using the gradient of the loss function with respect to those parameters. PyTorch has many different <a class="reference external" href="https://pytorch.org/docs/stable/optim.html#module-torch.optim">optimizers</a> available, and it is worthwhile to try out some of the different ones. Stochastic Gradient Descent (SGD) is one of the simplest, so we’ll start here. The <code class="docutils literal notranslate"><span class="pre">lr</span></code> parameter is the
‘learning rate,’ or how ambitious the optimizer should be in taking descent steps. Tuning this requires a bit of trial and error: you want the learning rate to be small enough so that the algorithm doesn’t diverge but large enough so that the optimization completes in a reasonable amount of time.</p>
</section>
<section id="Loss-functions">
<h2>Loss functions<a class="headerlink" href="#Loss-functions" title="Permalink to this heading">¶</a></h2>
<p>In the parlance of the machine learning community, one defines “loss” functions comparing models to data. For regularized maximum likelihood imaging, the most fundamental loss function we’ll use is the <a class="reference external" href="../api.html#mpol.losses.loss_fn">data likelihood</a> or the <span class="math notranslate nohighlight">\(\chi^2\)</span> value comparing the model visibilities to the data visibilities. For this introductory tutorial, we’ll use only the data likelihood loss function to start, but you should know that because imaging is an ill-defined inverse
problem, this is not a sufficient constraint by itself. In later tutorials, we will apply regularization to narrow the set of possible images towards ones that we believe are more realistic. The <a class="reference external" href="../api.html#module-mpol.losses">mpol.losses</a> module contains several loss functions currently popular in the literature, so you can experiment to see which best suits your application.</p>
</section>
<section id="Gradient-descent">
<h2>Gradient descent<a class="headerlink" href="#Gradient-descent" title="Permalink to this heading">¶</a></h2>
<p>Let’s walk through how we calculate a loss value and optimize the parameters. To start, let’s <a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">examine the parameters of the model</a></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
OrderedDict([(&#39;bcube.base_cube&#39;,
              tensor([[[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       ...,
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]]],
                     dtype=torch.float64)),
             (&#39;conv_layer.m.weight&#39;,
              tensor([[[[0.0625, 0.1250, 0.0625],
                        [0.1250, 0.2500, 0.1250],
                        [0.0625, 0.1250, 0.0625]]]], dtype=torch.float64)),
             (&#39;conv_layer.m.bias&#39;, tensor([0.], dtype=torch.float64))])
</pre></div></div>
</div>
<p>These are the default values that were used to initialize the <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a> component of the <a class="reference external" href="../api.html#mpol.precomposed.SimpleNet">SimpleNet</a>.</p>
<p>For demonstration purposes, lets access and plot the base cube with matplotlib. In a normal workflow you probably won’t need to do this, but to access the basecube in sky orientation, we do</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bcube_pytorch</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">packed_cube_to_sky_cube</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">bcube</span><span class="o">.</span><span class="n">base_cube</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">bcube</span></code> is still a PyTorch tensor, but matplotlib requires numpy arrays. To convert back, we need to first <a class="reference external" href="https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor">“detach” the computational graph</a> from the PyTorch tensor (used to propagate gradients) and then call the numpy conversion routine.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bcube_numpy</span> <span class="o">=</span> <span class="n">bcube_pytorch</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bcube_numpy</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(1, 800, 800)
</pre></div></div>
</div>
<p>lastly, we remove the channel dimension to plot the 2D image using <code class="docutils literal notranslate"><span class="pre">np.squeeze</span></code></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">bcube_numpy</span><span class="p">),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.colorbar.Colorbar at 0x7efefca5c850&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/ci-tutorials_optimization_26_1.png" class="no-scaled-link" src="../_images/ci-tutorials_optimization_26_1.png" style="width: 468px; height: 393px;" />
</div>
</div>
<p>A blank image is not that exciting, but hopefully this demonstrates the state of the parameters at the start of optimization.</p>
<p>Because we’ll want to compute a clean set of gradient values in a later step, we “zero out” any gradients attached to the tensor components so that they aren’t counted twice.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Most modules in MPoL are designed to work in a “feed forward” manner, which means base parameters are processed through the network to predict model visibilites for comparison with data. We can calculate the full visibility cube corresponding to the current pixel values of the <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vis</span> <span class="o">=</span> <span class="n">rml</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[ 1.1481e+01+0.0000e+00j,  7.1800e-03+2.8196e-05j,
          -7.1797e-03-5.6390e-05j,  ...,
           7.1791e-03-8.4581e-05j, -7.1797e-03+5.6390e-05j,
           7.1800e-03-2.8196e-05j],
         [ 7.1800e-03+2.8196e-05j,  4.4902e-06+3.5266e-08j,
          -4.4899e-06-5.2898e-08j,  ...,
           4.4899e-06-3.5264e-08j, -4.4902e-06+1.7633e-08j,
           4.4903e-06+4.9217e-19j],
         [-7.1797e-03-5.6390e-05j, -4.4899e-06-5.2898e-08j,
           4.4895e-06+7.0527e-08j,  ...,
          -4.4899e-06+1.7632e-08j,  4.4901e-06-6.4302e-19j,
          -4.4902e-06-1.7633e-08j],
         ...,
         [ 7.1791e-03-8.4581e-05j,  4.4899e-06-3.5264e-08j,
          -4.4899e-06+1.7632e-08j,  ...,
           4.4885e-06-1.0578e-07j, -4.4891e-06+8.8154e-08j,
           4.4895e-06-7.0526e-08j],
         [-7.1797e-03+5.6390e-05j, -4.4902e-06+1.7633e-08j,
           4.4901e-06+6.4011e-19j,  ...,
          -4.4891e-06+8.8154e-08j,  4.4895e-06-7.0527e-08j,
          -4.4899e-06+5.2898e-08j],
         [ 7.1800e-03-2.8196e-05j,  4.4903e-06-4.9292e-19j,
          -4.4902e-06-1.7633e-08j,  ...,
           4.4895e-06-7.0526e-08j, -4.4899e-06+5.2898e-08j,
           4.4902e-06-3.5266e-08j]]], dtype=torch.complex128,
       grad_fn=&lt;MulBackward0&gt;)
</pre></div></div>
</div>
<p>Of course, these aren’t that exciting since they just reflect the constant value image.</p>
<p>But, exciting things are about to happen! We can calculate the loss between these model visibilities and the data</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate a loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">nll_gridded</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">dset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3.124348303800103
</pre></div></div>
</div>
<p>and then we can calculate the gradient of the loss function with respect to the parameters</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>We can even visualize what the gradient of the <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a> looks like (using a similar <code class="docutils literal notranslate"><span class="pre">.detach()</span></code> call as before)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">packed_cube_to_sky_cube</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">bcube</span><span class="o">.</span><span class="n">base_cube</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="p">),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.colorbar.Colorbar at 0x7efefc875370&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/ci-tutorials_optimization_37_1.png" class="no-scaled-link" src="../_images/ci-tutorials_optimization_37_1.png" style="width: 441px; height: 414px;" />
</div>
</div>
<p>The gradient image points in the direction of lower loss values. So the final step is to add the gradient image to the base image in order to advance base parameters in the direction of the minimum loss value. This process is called gradient descent, and can be extremely useful for optimizing large dimensional parameter spaces (like images). The optimizer carries out the addition of the gradient</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>We can see that the parameter values have changed</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
OrderedDict([(&#39;bcube.base_cube&#39;,
              tensor([[[0.1532, 0.1587, 0.1637,  ..., 0.1354, 0.1414, 0.1474],
                       [0.1436, 0.1491, 0.1541,  ..., 0.1257, 0.1318, 0.1378],
                       [0.1340, 0.1395, 0.1445,  ..., 0.1161, 0.1222, 0.1282],
                       ...,
                       [0.1818, 0.1872, 0.1922,  ..., 0.1643, 0.1703, 0.1761],
                       [0.1723, 0.1778, 0.1828,  ..., 0.1548, 0.1607, 0.1666],
                       [0.1628, 0.1683, 0.1733,  ..., 0.1451, 0.1511, 0.1570]]],
                     dtype=torch.float64)),
             (&#39;conv_layer.m.weight&#39;,
              tensor([[[[0.0625, 0.1250, 0.0625],
                        [0.1250, 0.2500, 0.1250],
                        [0.0625, 0.1250, 0.0625]]]], dtype=torch.float64)),
             (&#39;conv_layer.m.bias&#39;, tensor([0.], dtype=torch.float64))])
</pre></div></div>
</div>
<p>as has the base image</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">packed_cube_to_sky_cube</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">bcube</span><span class="o">.</span><span class="n">base_cube</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.colorbar.Colorbar at 0x7efefc7da280&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/ci-tutorials_optimization_43_1.png" class="no-scaled-link" src="../_images/ci-tutorials_optimization_43_1.png" style="width: 460px; height: 393px;" />
</div>
</div>
</section>
<section id="Iterating-the-training-Loop">
<h2>Iterating the training Loop<a class="headerlink" href="#Iterating-the-training-Loop" title="Permalink to this heading">¶</a></h2>
<p>Now that we’ve covered how to use gradient descent to optimize a set of image parameters, let’s wrap these steps into a training loop and iterate a few hundred times to converge to a final product.</p>
<p>In addition to the steps just outlined, we’ll also track the loss values as we optimize.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">loss_tracker</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">rml</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># get the predicted model</span>
    <span class="n">vis</span> <span class="o">=</span> <span class="n">rml</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>

    <span class="c1"># calculate a loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">nll_gridded</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">dset</span><span class="p">)</span>

    <span class="n">loss_tracker</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># calculate gradients of parameters</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># update the model parameters</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 31.8 s, sys: 8.6 s, total: 40.4 s
Wall time: 25.3 s
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_tracker</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;loss&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/ci-tutorials_optimization_46_1.png" class="no-scaled-link" src="../_images/ci-tutorials_optimization_46_1.png" style="width: 469px; height: 451px;" />
</div>
</div>
<p>and we see that we’ve reasonably converged to a set of parameters without much further improvement in the loss value.</p>
<p>All of the method presented here can be sped up using GPU acceleration on certain Nvidia GPUs. To learn more about this, please see the <a class="reference external" href="gpu_setup.html">GPU Setup Tutorial</a>.</p>
</section>
<section id="Visualizing-output">
<h2>Visualizing output<a class="headerlink" href="#Visualizing-output" title="Permalink to this heading">¶</a></h2>
<p>Let’s visualize the final product. The bounds for <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.imshow</span></code> are available in the <code class="docutils literal notranslate"><span class="pre">img_ext</span></code> parameter.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s see what one channel of the image looks like</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">sky_cube</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.colorbar.Colorbar at 0x7efefc68fd90&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/ci-tutorials_optimization_49_1.png" class="no-scaled-link" src="../_images/ci-tutorials_optimization_49_1.png" style="width: 424px; height: 393px;" />
</div>
</div>
</section>
<section id="Wrapup">
<h2>Wrapup<a class="headerlink" href="#Wrapup" title="Permalink to this heading">¶</a></h2>
<p>And there you have it, an image optimized to fit the data. To be honest, the results aren’t great—that’s because we’ve used minimal regularization in the form of the functional basis set we chose that automatically enforced image positivity (see the <a class="reference external" href="../api.html#mpol.images.BaseCube">BaseCube</a> documentation). Otherwise, our only contribution to the loss function is the data likelihood. This means it’s easy for the lower signal-to-noise visibilities at longer baselines to dominate the image
appearance (not unlike “uniform”ly weighted images).</p>
<p>In the following tutorials we’ll examine how to set up additional regularizer terms that can yield more desireable image characteristics.</p>
<p>Hopefully this tutorial has demonstrated the core concepts of synthesizing an image with MPoL. If you have any questions about the process, please feel free to reach out and start a <a class="reference external" href="https://github.com/MPoL-dev/MPoL/discussions">GitHub discussion</a>. If you spot a bug or have an idea to improve these tutorials, please raise a <a class="reference external" href="https://github.com/MPoL-dev/MPoL/issues">GitHub issue</a> or better yet submit a pull request.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="crossvalidation.html" class="btn btn-neutral float-right" title="Cross validation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="gridder.html" class="btn btn-neutral float-left" title="Gridding and diagnostic images" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-21, Ian Czekala

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>


      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-5472810-8', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>