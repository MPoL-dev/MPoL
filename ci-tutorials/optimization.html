
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Intro to MPoL Optimization &#8212; MPoL 0.1.13 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="https://buttons.github.io/buttons.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Likelihood functions and model visibilities" href="loose-visibilities.html" />
    <link rel="prev" title="Gridding and diagnostic images" href="gridder.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">MPoL 0.1.13 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  User Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../rml_intro.html">
   Introduction to Regularized Maximum Likelihood Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   MPoL Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../units-and-conventions.html">
   Units and Conventions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../developer-documentation.html">
   Developer Documentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../api.html">
   API
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="PyTorch.html">
   Introduction to PyTorch: Tensors and Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gridder.html">
   Gridding and diagnostic images
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Intro to MPoL Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="loose-visibilities.html">
   Likelihood functions and model visibilities
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="crossvalidation.html">
   Cross validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gpu_setup.html">
   GPU Acceleration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="initializedirtyimage.html">
   Initializing with the Dirty Image
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../large-tutorials/HD143006_part_1.html">
   HD143006 Tutorial Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../large-tutorials/HD143006_part_2.html">
   HD143006 Tutorial Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fakedata.html">
   Making a Mock Dataset
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../changelog.html">
   Changelog
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/MPoL-dev/MPoL"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/ci-tutorials/optimization.md.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gridding-recap">
   Gridding recap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-pytorch-dataset">
   The PyTorch dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-an-image-model">
   Building an image model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breaking-down-the-training-loop">
   Breaking down the training loop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions">
   Loss functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   Gradient descent
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iterating-the-training-loop">
   Iterating the training Loop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-output">
   Visualizing output
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wrapup">
   Wrapup
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Intro to MPoL Optimization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gridding-recap">
   Gridding recap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-pytorch-dataset">
   The PyTorch dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-an-image-model">
   Building an image model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breaking-down-the-training-loop">
   Breaking down the training loop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions">
   Loss functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   Gradient descent
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iterating-the-training-loop">
   Iterating the training Loop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-output">
   Visualizing output
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wrapup">
   Wrapup
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> notebook_setup
</pre></div>
</div>
</div>
</details>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="intro-to-mpol-optimization">
<h1>Intro to MPoL Optimization<a class="headerlink" href="#intro-to-mpol-optimization" title="Permalink to this headline">#</a></h1>
<p>In this tutorial, we’ll construct an optimization loop demonstrating how we can use MPoL to synthesize a basic image. We’ll continue with the dataset described in the <a class="reference internal" href="gridder.html"><span class="doc std std-doc">Gridding and Diagnostic Images</span></a> tutorial.</p>
<section id="gridding-recap">
<h2>Gridding recap<a class="headerlink" href="#gridding-recap" title="Permalink to this headline">#</a></h2>
<p>Let’s set up the <a class="reference internal" href="../api.html#mpol.gridding.Gridder" title="mpol.gridding.Gridder"><code class="xref py py-class docutils literal notranslate"><span class="pre">Gridder</span></code></a> and <a class="reference internal" href="../api.html#mpol.coordinates.GridCoords" title="mpol.coordinates.GridCoords"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridCoords</span></code></a> objects as before</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">astropy.utils.data</span> <span class="kn">import</span> <span class="n">download_file</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">SVG</span><span class="p">,</span> <span class="n">display</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpol</span> <span class="kn">import</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">gridding</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">precomposed</span><span class="p">,</span> <span class="n">utils</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the mock dataset of the ALMA logo</span>
<span class="n">fname</span> <span class="o">=</span> <span class="n">download_file</span><span class="p">(</span>
    <span class="s2">&quot;https://zenodo.org/record/4930016/files/logo_cube.noise.npz&quot;</span><span class="p">,</span>
    <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pkgname</span><span class="o">=</span><span class="s2">&quot;mpol&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># this is a multi-channel dataset... for demonstration purposes we&#39;ll use</span>
<span class="c1"># only the central, single channel</span>
<span class="n">chan</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="n">uu</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;uu&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">vv</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;vv&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="n">chan</span><span class="p">]</span>
<span class="n">data_re</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data_im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the image dimensions, as in the previous tutorial</span>
<span class="n">coords</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">GridCoords</span><span class="p">(</span><span class="n">cell_size</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">npix</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<span class="n">gridder</span> <span class="o">=</span> <span class="n">gridding</span><span class="o">.</span><span class="n">Gridder</span><span class="p">(</span>
    <span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span>
    <span class="n">uu</span><span class="o">=</span><span class="n">uu</span><span class="p">,</span>
    <span class="n">vv</span><span class="o">=</span><span class="n">vv</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
    <span class="n">data_re</span><span class="o">=</span><span class="n">data_re</span><span class="p">,</span>
    <span class="n">data_im</span><span class="o">=</span><span class="n">data_im</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-pytorch-dataset">
<h2>The PyTorch dataset<a class="headerlink" href="#the-pytorch-dataset" title="Permalink to this headline">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title">Cell-averaging</p>
<p>The visibility averaging step performed by the gridder is a weighted average that is numerically equivalent to “uniform” weighting of the visibilities; this does not mean that MPoL or RML only produces images that have “uniform” weighting, however. The gridder also propagates the uncertainties from the individual visibilities to an uncertainty on the averaged visibility cell. When MPoL <em>forward-models</em> the visibility dataset and evaluates model image against the data, these uncertainties are used in a likelihood function, which is combined with priors/regularizers and the numerical results will be the same whether or not the likelihood function is computed using the gridded or <a class="reference internal" href="loose-visibilities.html"><span class="doc std std-doc">ungridded</span></a> visibilities. By contrast, dirty images are a direct inverse Fourier transform of the gridded visibility data and depend on whether the visibilities were weighted with uniform, natural, or Briggs weighting schemes.</p>
</aside>
<p>Now we will export the visibilities to a PyTorch dataset to use in the imaging loop. The <a class="reference internal" href="../api.html#mpol.gridding.Gridder.to_pytorch_dataset" title="mpol.gridding.Gridder.to_pytorch_dataset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">mpol.gridding.Gridder.to_pytorch_dataset()</span></code></a> routine performs a weighted average all of the visibilities to the Fourier grid cells and exports the visibilities to cube-like PyTorch tensors. To keep things simple in this tutorial, we are only using a single channel. But you could just as easily export a multi-channel dataset. Note that the <a class="reference internal" href="../api.html#mpol.gridding.Gridder.to_pytorch_dataset" title="mpol.gridding.Gridder.to_pytorch_dataset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_pytorch_dataset()</span></code></a> routine automatically checks the visibility scatter and raises a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code> if the empirically-estimated scatter exceeds that expected from the provided dataset weights. For more information, see the end of the <a class="reference internal" href="gridder.html"><span class="doc std std-doc">Gridding and Diagnostic Images Tutorial</span></a>.</p>
<p>In the following <a class="reference internal" href="loose-visibilities.html"><span class="doc std std-doc">tutorial on the NuFFT</span></a>, we’ll explore an alternate MPoL layer that avoids gridding the visibilities all together. This approach may be more accurate for certain applications, but is usually slower to execute than the gridding approach described in this tutorial. For that reason, we recommend starting with the default gridding approach and only moving to the NuFFT layers once you are reasonably happy with the images you are getting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dset</span> <span class="o">=</span> <span class="n">gridder</span><span class="o">.</span><span class="n">to_pytorch_dataset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;this dataset has </span><span class="si">{:}</span><span class="s2"> channel&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">nchan</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>this dataset has 1 channel
</pre></div>
</div>
</div>
</div>
</section>
<section id="building-an-image-model">
<h2>Building an image model<a class="headerlink" href="#building-an-image-model" title="Permalink to this headline">#</a></h2>
<p>MPoL provides “modules” to build and optimize complex imaging workflows, not dissimilar to how a deep neural network might be constructed. We’ve bundled the most common modules for imaging together in a <a class="reference internal" href="../api.html#mpol.precomposed.SimpleNet" title="mpol.precomposed.SimpleNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.precomposed.SimpleNet</span></code></a> meta-module, which we’ll use here.</p>
<p>This diagram shows how the primitive modules, like <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a>, <a class="reference internal" href="../api.html#mpol.images.ImageCube" title="mpol.images.ImageCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.ImageCube</span></code></a>, etc… are connected together to form <a class="reference internal" href="../api.html#mpol.precomposed.SimpleNet" title="mpol.precomposed.SimpleNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.precomposed.SimpleNet</span></code></a>. In this workflow, the pixel values of the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a> are the core model parameters representing the image. More information about all of these components is available in the <a class="reference internal" href="../api.html#api-reference-label"><span class="std std-ref">API documentation</span></a>.</p>
<div class="mermaid">
            graph TD
    subgraph SimpleNet
    bc(BaseCube) --&gt; HannConvCube
    HannConvCube --&gt; ImageCube
    ImageCube --&gt; FourierLayer
    end
    FourierLayer --&gt; il([Loss])
    ad[[Dataset]] --&gt; il([Loss])

        </div><p>It isn’t necessary to construct a meta-module to do RML imaging with MPoL, though it often helps organize your code. If we so desired, we could connect the individual modules together ourselves ourselves following the SimpleNet source code as an example (<a class="reference internal" href="../api.html#mpol.precomposed.SimpleNet" title="mpol.precomposed.SimpleNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.precomposed.SimpleNet</span></code></a>) and swap in/out modules as we saw fit.</p>
<p>We then initialize SimpleNet with the relevant information</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span> <span class="o">=</span> <span class="n">precomposed</span><span class="o">.</span><span class="n">SimpleNet</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span> <span class="n">nchan</span><span class="o">=</span><span class="n">dset</span><span class="o">.</span><span class="n">nchan</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="breaking-down-the-training-loop">
<h2>Breaking down the training loop<a class="headerlink" href="#breaking-down-the-training-loop" title="Permalink to this headline">#</a></h2>
<p>Our goal for the rest of the tutorial is to set up a loop that will</p>
<ol class="arabic simple">
<li><p>evaluate the current model against a loss function</p></li>
<li><p>calculate the gradients of the loss w.r.t. the model</p></li>
<li><p>advance the model parameters in the direction to minimize the loss function</p></li>
</ol>
<p>We’ll start by creating the optimizer</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">8000.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The role of the optimizer is to advance the parameters (in this case, the pixel values of the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a> using the gradient of the loss function with respect to those parameters. PyTorch has many different <a class="reference external" href="https://pytorch.org/docs/stable/optim.html#module-torch.optim">optimizers</a> available, and it is worthwhile to try out some of the different ones. Stochastic Gradient Descent (SGD) is one of the simplest, so we’ll start here. The <code class="docutils literal notranslate"><span class="pre">lr</span></code> parameter is the ‘learning rate,’ or how ambitious the optimizer should be in taking descent steps. Tuning this requires a bit of trial and error: you want the learning rate to be small enough so that the algorithm doesn’t diverge but large enough so that the optimization completes in a reasonable amount of time.</p>
</section>
<section id="loss-functions">
<h2>Loss functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">#</a></h2>
<p>In the parlance of the machine learning community, one defines “loss” functions comparing models to data. For regularized maximum likelihood imaging, the most fundamental loss function we’ll use is the <code class="xref py py-func docutils literal notranslate"><span class="pre">mpol.losses.loss_fn()</span></code> or the <span class="math notranslate nohighlight">\(\chi^2\)</span> value comparing the model visibilities to the data visibilities. For this introductory tutorial, we’ll use only the data likelihood loss function to start, but you should know that because imaging is an ill-defined inverse problem, this is <strong>not a sufficient constraint</strong> by itself. In later tutorials, we will apply regularization to narrow the set of possible images towards ones that we believe are more realistic. The <a class="reference internal" href="../api.html#module-mpol.losses" title="mpol.losses"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mpol.losses</span></code></a> module contains several loss functions currently popular in the literature, so you can experiment to see which best suits your application.</p>
</section>
<section id="gradient-descent">
<h2>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">#</a></h2>
<p>Let’s walk through how we calculate a loss value and optimize the parameters. To start, let’s <a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">examine the parameters of the model</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;bcube.base_cube&#39;,
              tensor([[[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       ...,
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],
                       [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]]],
                     dtype=torch.float64)),
             (&#39;conv_layer.m.weight&#39;,
              tensor([[[[0.0625, 0.1250, 0.0625],
                        [0.1250, 0.2500, 0.1250],
                        [0.0625, 0.1250, 0.0625]]]], dtype=torch.float64)),
             (&#39;conv_layer.m.bias&#39;, tensor([0.], dtype=torch.float64))])
</pre></div>
</div>
</div>
</div>
<p>These are the default values that were used to initialize the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a> component of the <a class="reference internal" href="../api.html#mpol.precomposed.SimpleNet" title="mpol.precomposed.SimpleNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.precomposed.SimpleNet</span></code></a>.</p>
<p>For demonstration purposes, lets access and plot the base cube with matplotlib. In a normal workflow you probably won’t need to do this, but to access the basecube in sky orientation, we do</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bcube_pytorch</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">packed_cube_to_sky_cube</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">bcube</span><span class="o">.</span><span class="n">base_cube</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">bcube</span></code> is still a PyTorch tensor, but matplotlib requires numpy arrays. To convert back, we need to first <a class="reference external" href="https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor">“detach” the computational graph</a> from the PyTorch tensor (used to propagate gradients) and then call the numpy conversion routine.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bcube_numpy</span> <span class="o">=</span> <span class="n">bcube_pytorch</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bcube_numpy</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 800, 800)
</pre></div>
</div>
</div>
</div>
<p>lastly, we remove the channel dimension to plot the 2D image using <code class="docutils literal notranslate"><span class="pre">np.squeeze</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">bcube_numpy</span><span class="p">),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \alpha \cos \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fcd6e2231f0&gt;
</pre></div>
</div>
<img alt="../_images/861f54db731f61ad91eaf36806482999dce5ca72c578d50070ac6724bda8f0cc.png" src="../_images/861f54db731f61ad91eaf36806482999dce5ca72c578d50070ac6724bda8f0cc.png" />
</div>
</div>
<p>A blank image is not that exciting, but hopefully this demonstrates the state of the parameters at the start of optimization.</p>
<p>Because we’ll want to compute a clean set of gradient values in a later step, we “zero out” any gradients attached to the tensor components so that they aren’t counted twice.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Most modules in MPoL are designed to work in a “feed forward” manner, which means base parameters are processed through the network to predict model visibilites for comparison with data. We can calculate the full visibility cube corresponding to the current pixel values of the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vis</span> <span class="o">=</span> <span class="n">rml</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 1.1481e+01+0.0000e+00j,  7.1800e-03+2.8196e-05j,
          -7.1797e-03-5.6390e-05j,  ...,
           7.1791e-03-8.4581e-05j, -7.1797e-03+5.6390e-05j,
           7.1800e-03-2.8196e-05j],
         [ 7.1800e-03+2.8196e-05j,  4.4902e-06+3.5266e-08j,
          -4.4899e-06-5.2898e-08j,  ...,
           4.4899e-06-3.5264e-08j, -4.4902e-06+1.7633e-08j,
           4.4903e-06-3.8083e-22j],
         [-7.1797e-03-5.6390e-05j, -4.4899e-06-5.2898e-08j,
           4.4895e-06+7.0527e-08j,  ...,
          -4.4899e-06+1.7632e-08j,  4.4901e-06+1.1980e-21j,
          -4.4902e-06-1.7633e-08j],
         ...,
         [ 7.1791e-03-8.4581e-05j,  4.4899e-06-3.5264e-08j,
          -4.4899e-06+1.7632e-08j,  ...,
           4.4885e-06-1.0578e-07j, -4.4891e-06+8.8154e-08j,
           4.4895e-06-7.0526e-08j],
         [-7.1797e-03+5.6390e-05j, -4.4902e-06+1.7633e-08j,
           4.4901e-06-1.6480e-21j,  ...,
          -4.4891e-06+8.8154e-08j,  4.4895e-06-7.0527e-08j,
          -4.4899e-06+5.2898e-08j],
         [ 7.1800e-03-2.8196e-05j,  4.4903e-06-1.4745e-21j,
          -4.4902e-06-1.7633e-08j,  ...,
           4.4895e-06-7.0526e-08j, -4.4899e-06+5.2898e-08j,
           4.4902e-06-3.5266e-08j]]], dtype=torch.complex128,
       grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Of course, these aren’t that exciting since they just reflect the constant value image.</p>
<p>But, exciting things are about to happen! We can calculate the loss between these model visibilities and the data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate a loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">nll_gridded</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">dset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.124348303800103
</pre></div>
</div>
</div>
</div>
<p>and then we can calculate the gradient of the loss function with respect to the parameters</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can even visualize what the gradient of the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a> looks like (using a similar <code class="docutils literal notranslate"><span class="pre">.detach()</span></code> call as before)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">packed_cube_to_sky_cube</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">bcube</span><span class="o">.</span><span class="n">base_cube</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="p">),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \alpha \cos \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fcd6c5d3dc0&gt;
</pre></div>
</div>
<img alt="../_images/628bf27fcb379f189dceaba6569beeeeb474e836c25ac6b7c17a072acd8648fa.png" src="../_images/628bf27fcb379f189dceaba6569beeeeb474e836c25ac6b7c17a072acd8648fa.png" />
</div>
</div>
<p>The gradient image points in the direction of lower loss values. So the final step is to add the gradient image to the base image in order to advance base parameters in the direction of the minimum loss value. This process is called gradient descent, and can be extremely useful for optimizing large dimensional parameter spaces (like images). The optimizer carries out the addition of the gradient</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can see that the parameter values have changed</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rml</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;bcube.base_cube&#39;,
              tensor([[[0.1532, 0.1587, 0.1637,  ..., 0.1354, 0.1414, 0.1474],
                       [0.1436, 0.1491, 0.1541,  ..., 0.1257, 0.1318, 0.1378],
                       [0.1340, 0.1395, 0.1445,  ..., 0.1161, 0.1222, 0.1282],
                       ...,
                       [0.1818, 0.1872, 0.1922,  ..., 0.1643, 0.1703, 0.1761],
                       [0.1723, 0.1778, 0.1828,  ..., 0.1548, 0.1607, 0.1666],
                       [0.1628, 0.1683, 0.1733,  ..., 0.1451, 0.1511, 0.1570]]],
                     dtype=torch.float64)),
             (&#39;conv_layer.m.weight&#39;,
              tensor([[[[0.0625, 0.1250, 0.0625],
                        [0.1250, 0.2500, 0.1250],
                        [0.0625, 0.1250, 0.0625]]]], dtype=torch.float64)),
             (&#39;conv_layer.m.bias&#39;, tensor([0.], dtype=torch.float64)),
             (&#39;fcube.vis&#39;,
              tensor([[[ 1.1481e+01+0.0000e+00j,  7.1800e-03+2.8196e-05j,
                        -7.1797e-03-5.6390e-05j,  ...,
                         7.1791e-03-8.4581e-05j, -7.1797e-03+5.6390e-05j,
                         7.1800e-03-2.8196e-05j],
                       [ 7.1800e-03+2.8196e-05j,  4.4902e-06+3.5266e-08j,
                        -4.4899e-06-5.2898e-08j,  ...,
                         4.4899e-06-3.5264e-08j, -4.4902e-06+1.7633e-08j,
                         4.4903e-06-3.8083e-22j],
                       [-7.1797e-03-5.6390e-05j, -4.4899e-06-5.2898e-08j,
                         4.4895e-06+7.0527e-08j,  ...,
                        -4.4899e-06+1.7632e-08j,  4.4901e-06+1.1980e-21j,
                        -4.4902e-06-1.7633e-08j],
                       ...,
                       [ 7.1791e-03-8.4581e-05j,  4.4899e-06-3.5264e-08j,
                        -4.4899e-06+1.7632e-08j,  ...,
                         4.4885e-06-1.0578e-07j, -4.4891e-06+8.8154e-08j,
                         4.4895e-06-7.0526e-08j],
                       [-7.1797e-03+5.6390e-05j, -4.4902e-06+1.7633e-08j,
                         4.4901e-06-1.6480e-21j,  ...,
                        -4.4891e-06+8.8154e-08j,  4.4895e-06-7.0527e-08j,
                        -4.4899e-06+5.2898e-08j],
                       [ 7.1800e-03-2.8196e-05j,  4.4903e-06-1.4745e-21j,
                        -4.4902e-06-1.7633e-08j,  ...,
                         4.4895e-06-7.0526e-08j, -4.4899e-06+5.2898e-08j,
                         4.4902e-06-3.5266e-08j]]], dtype=torch.complex128))])
</pre></div>
</div>
</div>
</div>
<p>as has the base image</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">packed_cube_to_sky_cube</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">bcube</span><span class="o">.</span><span class="n">base_cube</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \alpha \cos \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fcd6c4d0220&gt;
</pre></div>
</div>
<img alt="../_images/e4632e540366f8a91256a0fa332b63e619f2dafc7a6c3deda6166e5579516d44.png" src="../_images/e4632e540366f8a91256a0fa332b63e619f2dafc7a6c3deda6166e5579516d44.png" />
</div>
</div>
</section>
<section id="iterating-the-training-loop">
<h2>Iterating the training Loop<a class="headerlink" href="#iterating-the-training-loop" title="Permalink to this headline">#</a></h2>
<p>Now that we’ve covered how to use gradient descent to optimize a set of image parameters, let’s wrap these steps into a training loop and iterate a few hundred times to converge to a final product.</p>
<p>In addition to the steps just outlined, we’ll also track the loss values as we optimize.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">loss_tracker</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">rml</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># get the predicted model</span>
    <span class="n">vis</span> <span class="o">=</span> <span class="n">rml</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>

    <span class="c1"># calculate a loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">nll_gridded</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">dset</span><span class="p">)</span>

    <span class="n">loss_tracker</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># calculate gradients of parameters</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># update the model parameters</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 32.9 s, sys: 7.72 s, total: 40.6 s
Wall time: 24.6 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_tracker</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;loss&#39;)
</pre></div>
</div>
<img alt="../_images/b267f36a40ee3ebad4d3e8ce5cc07944476dbcd8c9babfd1d8f41f8f9a8f4a25.png" src="../_images/b267f36a40ee3ebad4d3e8ce5cc07944476dbcd8c9babfd1d8f41f8f9a8f4a25.png" />
</div>
</div>
<p>and we see that we’ve reasonably converged to a set of parameters without much further improvement in the loss value.</p>
<p>All of the method presented here can be sped up using GPU acceleration on certain Nvidia GPUs. To learn more about this, please see the <a class="reference internal" href="gpu_setup.html#gpu-reference-label"><span class="std std-ref">GPU Setup Tutorial</span></a>.</p>
</section>
<section id="visualizing-output">
<h2>Visualizing output<a class="headerlink" href="#visualizing-output" title="Permalink to this headline">#</a></h2>
<p>Let’s visualize the final product. The bounds for <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.imshow</span></code> are available in the <code class="docutils literal notranslate"><span class="pre">img_ext</span></code> parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s see what one channel of the image looks like</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">sky_cube</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">extent</span><span class="o">=</span><span class="n">rml</span><span class="o">.</span><span class="n">icube</span><span class="o">.</span><span class="n">coords</span><span class="o">.</span><span class="n">img_ext</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \alpha \cos \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\Delta \delta$ [$</span><span class="si">{}</span><span class="s2">^{\prime\prime}$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7fcd6c32e9d0&gt;
</pre></div>
</div>
<img alt="../_images/9b4ad0e1f387523f0d7a60848c332837d46aa36991da61a6c59b9ac82a280bf5.png" src="../_images/9b4ad0e1f387523f0d7a60848c332837d46aa36991da61a6c59b9ac82a280bf5.png" />
</div>
</div>
</section>
<section id="wrapup">
<h2>Wrapup<a class="headerlink" href="#wrapup" title="Permalink to this headline">#</a></h2>
<p>And there you have it, an image optimized to fit the data. To be honest, the results aren’t great—that’s because we’ve used minimal regularization in the form of the functional basis set we chose that automatically enforced image positivity (see the <a class="reference internal" href="../api.html#mpol.images.BaseCube" title="mpol.images.BaseCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.images.BaseCube</span></code></a> documentation). Otherwise, our only contribution to the loss function is the data likelihood. This means it’s easy for the lower signal-to-noise visibilities at longer baselines to dominate the image appearance (not unlike “uniform”ly weighted images).</p>
<p>In the following tutorials we’ll examine how to set up additional regularizer terms that can yield more desireable image characteristics.</p>
<p>Hopefully this tutorial has demonstrated the core concepts of synthesizing an image with MPoL. If you have any questions about the process, please feel free to reach out and start a <a class="reference external" href="https://github.com/MPoL-dev/MPoL/discussions">GitHub discussion</a>. If you spot a bug or have an idea to improve these tutorials, please raise a <a class="reference external" href="https://github.com/MPoL-dev/MPoL/issues">GitHub issue</a> or better yet submit a pull request.</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="gridder.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Gridding and diagnostic images</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="loose-visibilities.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Likelihood functions and model visibilities</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ian Czekala<br/>
  
      &copy; Copyright 2019-22, Ian Czekala.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>