
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Likelihood functions and model visibilities &#8212; MPoL 0.1.13 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="https://buttons.github.io/buttons.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cross validation" href="crossvalidation.html" />
    <link rel="prev" title="Intro to RML with MPoL" href="optimization.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">MPoL 0.1.13 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  User Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../rml_intro.html">
   Introduction to Regularized Maximum Likelihood Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   MPoL Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../units-and-conventions.html">
   Units and Conventions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../developer-documentation.html">
   Developer Documentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../api.html">
   API
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="PyTorch.html">
   Introduction to PyTorch: Tensors and Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gridder.html">
   Gridding and diagnostic images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optimization.html">
   Intro to RML with MPoL
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Likelihood functions and model visibilities
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="crossvalidation.html">
   Cross validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gpu_setup.html">
   GPU Acceleration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="initializedirtyimage.html">
   Initializing with the Dirty Image
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../large-tutorials/HD143006_part_1.html">
   HD143006 Tutorial Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../large-tutorials/HD143006_part_2.html">
   HD143006 Tutorial Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fakedata.html">
   Making a Mock Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../large-tutorials/pyro.html">
   Parametric Inference with Pyro
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../changelog.html">
   Changelog
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/MPoL-dev/MPoL"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/ci-tutorials/loose-visibilities.md.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mock-image">
   Mock image
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-mpol-fourier-nufft-object">
   The
   <code class="xref py py-class docutils literal notranslate">
    <span class="pre">
     mpol.fourier.NuFFT
    </span>
   </code>
   object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compared-to-the-mpol-gridding-dataaverager-object">
   Compared to the
   <code class="xref py py-class docutils literal notranslate">
    <span class="pre">
     mpol.gridding.DataAverager
    </span>
   </code>
   object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-plane-forward-model">
   Image-plane forward model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#producing-model-visibilities">
   Producing model visibilities
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluating-a-likelihood-function">
   Evaluating a likelihood function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preamble-for-a-completely-real-dataset">
     Preamble for a completely real dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#changes-for-complex-valued-fourier-data">
     Changes for complex-valued Fourier data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loose-visibility-log-likelihood">
     “Loose” visibility log likelihood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gridded-visibility-log-likelihood">
     Gridded visibility log likelihood
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalized-negative-log-likelihood-loss-function">
   Normalized negative log likelihood loss function
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Likelihood functions and model visibilities</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mock-image">
   Mock image
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-mpol-fourier-nufft-object">
   The
   <code class="xref py py-class docutils literal notranslate">
    <span class="pre">
     mpol.fourier.NuFFT
    </span>
   </code>
   object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compared-to-the-mpol-gridding-dataaverager-object">
   Compared to the
   <code class="xref py py-class docutils literal notranslate">
    <span class="pre">
     mpol.gridding.DataAverager
    </span>
   </code>
   object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-plane-forward-model">
   Image-plane forward model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#producing-model-visibilities">
   Producing model visibilities
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluating-a-likelihood-function">
   Evaluating a likelihood function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preamble-for-a-completely-real-dataset">
     Preamble for a completely real dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#changes-for-complex-valued-fourier-data">
     Changes for complex-valued Fourier data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loose-visibility-log-likelihood">
     “Loose” visibility log likelihood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gridded-visibility-log-likelihood">
     Gridded visibility log likelihood
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalized-negative-log-likelihood-loss-function">
   Normalized negative log likelihood loss function
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> notebook_setup
</pre></div>
</div>
</div>
</details>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="likelihood-functions-and-model-visibilities">
<h1>Likelihood functions and model visibilities<a class="headerlink" href="#likelihood-functions-and-model-visibilities" title="Permalink to this headline">#</a></h1>
<p>Typical interferometric datasets from ALMA may contain over 100,000 individual visibility measurements. As you saw in the <a class="reference internal" href="optimization.html"><span class="doc std std-doc">MPoL optimization introduction</span></a>, the basic MPoL workflow is to perform a weighted average of these individual visibilities to the <span class="math notranslate nohighlight">\(u,v\)</span> Fourier grid defined by a <a class="reference internal" href="../api.html#mpol.coordinates.GridCoords" title="mpol.coordinates.GridCoords"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.coordinates.GridCoords</span></code></a> object and calculate equivalent weights for those grid cells. This means that any forward-modeling application of MPoL need only carry the image model to the gridded Fourier plane, since likelihood evaluations can be done on a cell-to-cell basis. Depending on the dimensions of the Fourier grid, this can dramatically reduce the effective size of the dataset and speed up the computational time.</p>
<p>For some applications, though, it may be desireable to keep the dataset as individual visibility points and instead carry the image model all the way to these discrete points. This allows a direct comparison in the space of the ungridded data. Moreover, this allows a more thorough examination of visibility residuals for at least two reasons:</p>
<ol class="arabic simple">
<li><p>Residual visibilities may be “regridded” using some form of Briggs or natural weighting and then imaged with a dirty image. This improves point source sensitivity and may make faint residual structures easier to detect.</p></li>
<li><p>Individual visibility data might have relevant metadata that would otherwise be destroyed in a cell-averaging process. For example, perhaps visibilities from a particular execution block were incorrectly calibrated. It would be possible to spot such a data-defect if residual scatter were examined on a per-visibility, per-execution block basis.</p></li>
</ol>
<p>In this tutorial, we will explore the <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> object and how it may be used to compute individual visibilities.</p>
<section id="mock-image">
<h2>Mock image<a class="headerlink" href="#mock-image" title="Permalink to this headline">#</a></h2>
<p>We will use <span class="math notranslate nohighlight">\(u,v\)</span> locations from the same mock-dataset as before. So we’ll start by importing the relevant functions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">astropy.utils.data</span> <span class="kn">import</span> <span class="n">download_file</span>
</pre></div>
</div>
</div>
</div>
<p>and the relevant MPoL modules</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpol</span> <span class="kn">import</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">gridding</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">precomposed</span><span class="p">,</span> <span class="n">utils</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">fourier</span>
</pre></div>
</div>
</div>
</div>
<p>and loading the dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the mock dataset of the ALMA logo</span>
<span class="n">fname</span> <span class="o">=</span> <span class="n">download_file</span><span class="p">(</span>
    <span class="s2">&quot;https://zenodo.org/record/4930016/files/logo_cube.noise.npz&quot;</span><span class="p">,</span>
    <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pkgname</span><span class="o">=</span><span class="s2">&quot;mpol&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># this is a multi-channel dataset...</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="n">uu</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;uu&quot;</span><span class="p">]</span>
<span class="n">vv</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;vv&quot;</span><span class="p">]</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
<span class="n">data_re</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data_im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">nchan</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">uu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the image dimensions, as in the previous tutorial</span>
<span class="n">coords</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">GridCoords</span><span class="p">(</span><span class="n">cell_size</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">npix</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This dataset has multiple channels to it, which we’ll use to demonstrate some of the various features of the <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> object.</p>
</section>
<section id="the-mpol-fourier-nufft-object">
<h2>The <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> object<a class="headerlink" href="#the-mpol-fourier-nufft-object" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> object relies upon the functionality provided by the <a class="reference external" href="https://torchkbnufft.readthedocs.io/en/stable/">TorchKbNuFFT package</a>. Before going further, we encourage you to read the API documentation of the <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> object itself. There are two main modes of functionality to consider for this object, which depend on the dimensionality of your baseline arrays.</p>
<p>Paraphrasing from the <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> API documentation,</p>
<ul class="simple">
<li><p>If you provide baseline arrays <code class="docutils literal notranslate"><span class="pre">uu</span></code> and <code class="docutils literal notranslate"><span class="pre">vv</span></code> with a shape of (<code class="docutils literal notranslate"><span class="pre">nvis</span></code>), then it will be assumed that the spatial frequencies can be treated as constant with channel. This is likely a safe assumption for most spectral line datasets (but one you can check yourself using <a class="reference internal" href="../api.html#mpol.fourier.safe_baseline_constant_meters" title="mpol.fourier.safe_baseline_constant_meters"><code class="xref py py-func docutils literal notranslate"><span class="pre">mpol.fourier.safe_baseline_constant_meters()</span></code></a> or <a class="reference internal" href="../api.html#mpol.fourier.safe_baseline_constant_kilolambda" title="mpol.fourier.safe_baseline_constant_kilolambda"><code class="xref py py-func docutils literal notranslate"><span class="pre">mpol.fourier.safe_baseline_constant_kilolambda()</span></code></a>).</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">uu</span></code> and <code class="docutils literal notranslate"><span class="pre">vv</span></code> have a shape of (<code class="docutils literal notranslate"><span class="pre">nchan,</span> <span class="pre">nvis</span></code>), then it will be assumed that the spatial frequencies are different for each channel, and the spatial frequencies provided for each channel will be used.</p></li>
</ul>
<p>Let’s use the <a class="reference internal" href="../api.html#mpol.fourier.safe_baseline_constant_kilolambda" title="mpol.fourier.safe_baseline_constant_kilolambda"><code class="xref py py-func docutils literal notranslate"><span class="pre">mpol.fourier.safe_baseline_constant_kilolambda()</span></code></a> routine to check the status of the arrays in this dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fourier</span><span class="o">.</span><span class="n">safe_baseline_constant_kilolambda</span><span class="p">(</span><span class="n">uu</span><span class="p">,</span> <span class="n">vv</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">uv_cell_frac</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>So, we would be safe to proceed with using the <span class="math notranslate nohighlight">\(u,v\)</span> values from a single channel as representative. Let’s proceed with this assumption</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chan</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">uu_chan</span> <span class="o">=</span> <span class="n">uu</span><span class="p">[</span><span class="n">chan</span><span class="p">]</span>
<span class="n">vv_chan</span> <span class="o">=</span> <span class="n">vv</span><span class="p">[</span><span class="n">chan</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>and then use these values to initialize a <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> object</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nufft</span> <span class="o">=</span> <span class="n">fourier</span><span class="o">.</span><span class="n">NuFFT</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span> <span class="n">nchan</span><span class="o">=</span><span class="n">nchan</span><span class="p">,</span> <span class="n">uu</span><span class="o">=</span><span class="n">uu_chan</span><span class="p">,</span> <span class="n">vv</span><span class="o">=</span><span class="n">vv_chan</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s put the NuFFT aside for a moment while we initialize the <a class="reference internal" href="../api.html#mpol.gridding.DataAverager" title="mpol.gridding.DataAverager"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.gridding.DataAverager</span></code></a> object and create an image for use in the forward model.</p>
</section>
<section id="compared-to-the-mpol-gridding-dataaverager-object">
<h2>Compared to the <a class="reference internal" href="../api.html#mpol.gridding.DataAverager" title="mpol.gridding.DataAverager"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.gridding.DataAverager</span></code></a> object<a class="headerlink" href="#compared-to-the-mpol-gridding-dataaverager-object" title="Permalink to this headline">#</a></h2>
<p>As before, we simply send the visibilities to the object and export a <a class="reference internal" href="../api.html#mpol.datasets.GriddedDataset" title="mpol.datasets.GriddedDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.datasets.GriddedDataset</span></code></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">averager</span> <span class="o">=</span> <span class="n">gridding</span><span class="o">.</span><span class="n">DataAverager</span><span class="p">(</span>
    <span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span>
    <span class="n">uu</span><span class="o">=</span><span class="n">uu</span><span class="p">,</span>
    <span class="n">vv</span><span class="o">=</span><span class="n">vv</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
    <span class="n">data_re</span><span class="o">=</span><span class="n">data_re</span><span class="p">,</span>
    <span class="n">data_im</span><span class="o">=</span><span class="n">data_im</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">gridded_dset</span> <span class="o">=</span> <span class="n">averager</span><span class="o">.</span><span class="n">to_pytorch_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>And we can initialize a <a class="reference internal" href="../api.html#mpol.fourier.FourierCube" title="mpol.fourier.FourierCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.FourierCube</span></code></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flayer</span> <span class="o">=</span> <span class="n">fourier</span><span class="o">.</span><span class="n">FourierCube</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="image-plane-forward-model">
<h2>Image-plane forward model<a class="headerlink" href="#image-plane-forward-model" title="Permalink to this headline">#</a></h2>
<p>RML is fundamentally a forward-modeling application. To test and compare both the NuFFT and gridded approaches, we’ll use the same forward model.</p>
<p>We could start from a blank image, but we’ll make things slightly more interesting by setting the initial image to be a Gaussian in the image plane, constant across all channels</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gaussian parameters</span>
<span class="n">kw</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;delta_x&quot;</span><span class="p">:</span> <span class="mf">0.02</span><span class="p">,</span>  <span class="c1"># arcsec</span>
    <span class="s2">&quot;delta_y&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="s2">&quot;sigma_x&quot;</span><span class="p">:</span> <span class="mf">0.02</span><span class="p">,</span>
    <span class="s2">&quot;sigma_y&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="s2">&quot;Omega&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>  <span class="c1"># degrees</span>
<span class="p">}</span>

<span class="c1"># evaluate the Gaussian over the sky-plane, as np array</span>
<span class="n">img_packed</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">sky_gaussian_arcsec</span><span class="p">(</span>
    <span class="n">coords</span><span class="o">.</span><span class="n">packed_x_centers_2D</span><span class="p">,</span> <span class="n">coords</span><span class="o">.</span><span class="n">packed_y_centers_2D</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span>

<span class="c1"># broadcast to (nchan, npix, npix)</span>
<span class="n">img_packed_cube</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">img_packed</span><span class="p">,</span> <span class="p">(</span><span class="n">nchan</span><span class="p">,</span> <span class="n">coords</span><span class="o">.</span><span class="n">npix</span><span class="p">,</span> <span class="n">coords</span><span class="o">.</span><span class="n">npix</span><span class="p">))</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># convert img_packed to pytorch tensor</span>
<span class="n">img_packed_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">img_packed_cube</span><span class="p">)</span>
<span class="c1"># insert into ImageCube layer</span>
<span class="n">icube</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">ImageCube</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">,</span> <span class="n">nchan</span><span class="o">=</span><span class="n">nchan</span><span class="p">,</span> <span class="n">cube</span><span class="o">=</span><span class="n">img_packed_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="producing-model-visibilities">
<h2>Producing model visibilities<a class="headerlink" href="#producing-model-visibilities" title="Permalink to this headline">#</a></h2>
<p>The interesting part of the NuFFT is that it will carry an image plane model all the way to the Fourier plane in loose visibilities, resulting in a model visibility array the same shape as the original visibility data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vis_model_loose</span> <span class="o">=</span> <span class="n">nufft</span><span class="p">(</span><span class="n">icube</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loose model visibilities from the NuFFT have shape </span><span class="si">{:}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vis_model_loose</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The original loose data visibilities have shape </span><span class="si">{:}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loose model visibilities from the NuFFT have shape torch.Size([9, 325080])
The original loose data visibilities have shape (9, 325080)
</pre></div>
</div>
</div>
</div>
<p>By comparison, the <code class="xref py py-class docutils literal notranslate"><span class="pre">Gridder</span></code> object puts the visibilities onto a grid and exports a <a class="reference internal" href="../api.html#mpol.datasets.GriddedDataset" title="mpol.datasets.GriddedDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">GriddedDataset</span></code></a> object. These gridded data visibilities have the same dimensionality as the gridded model visibilities produced by the <a class="reference internal" href="../api.html#mpol.fourier.FourierCube" title="mpol.fourier.FourierCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">FourierCube</span></code></a> layer</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vis_model_gridded</span> <span class="o">=</span> <span class="n">flayer</span><span class="p">(</span><span class="n">icube</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gridded model visibilities from FourierCube have shape </span><span class="si">{:}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vis_model_gridded</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gridded data visibilities have shape </span><span class="si">{:}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gridded_dset</span><span class="o">.</span><span class="n">vis_gridded</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gridded model visibilities from FourierCube have shape torch.Size([9, 800, 800])
Gridded data visibilities have shape torch.Size([9, 800, 800])
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluating-a-likelihood-function">
<h2>Evaluating a likelihood function<a class="headerlink" href="#evaluating-a-likelihood-function" title="Permalink to this headline">#</a></h2>
<p>As we discussed in the <a class="reference internal" href="../rml_intro.html"><span class="doc std std-doc">Introduction to RML Imaging</span></a> a likelihood function is used to to evaluate the probability of the data given a model and its parameters.</p>
<section id="preamble-for-a-completely-real-dataset">
<h3>Preamble for a completely real dataset<a class="headerlink" href="#preamble-for-a-completely-real-dataset" title="Permalink to this headline">#</a></h3>
<p>If we had a dataset of only real values, for example, a bunch of values <span class="math notranslate nohighlight">\(\boldsymbol{Y}\)</span> at various <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> locations, and we wanted to fit a model of a line <span class="math notranslate nohighlight">\(M(x_i |\, \boldsymbol{\theta}) = m x_i + b\)</span> with parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta} = \{m, b\}\)</span>, then the full likelihood is a multi-dimensional Gaussian</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\boldsymbol{Y}|\,\boldsymbol{\theta}) = \frac{1}{[(2 \pi)^N \det \mathbf{\Sigma}]^{1/2}} \exp \left (- \frac{1}{2} \mathbf{R}^\mathrm{T} \mathbf{\Sigma}^{-1} \mathbf{R} \right )
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{R} = \boldsymbol{Y} - M(\boldsymbol{X} |\, \boldsymbol{\theta})\)</span> is a vector of residual visibilities and <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> is the covariance matrix of the data. The logarithm of the likelihood function is</p>
<div class="math notranslate nohighlight">
\[
\ln \mathcal{L}(\boldsymbol{Y}|\,\boldsymbol{\theta}) = - \frac{1}{2} \left ( N \ln 2 \pi +  \ln \det \mathbf{\Sigma} + \mathbf{R}^\mathrm{T} \mathbf{\Sigma}^{-1} \mathbf{R} \right ).
\]</div>
<p>When considering independent data within the same channel, the covariance matrix is a diagonal matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{\Sigma} = \begin{bmatrix}
\sigma_1^2 &amp; 0 &amp; \ldots &amp; 0 \\
0 &amp; \sigma_2^2 &amp; \ldots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; \sigma_N^2
\end{bmatrix}
\end{split}\]</div>
<p>and the logarithm of the likelihood can be reduced to the following expression</p>
<div class="math notranslate nohighlight">
\[
\ln \mathcal{L}(\boldsymbol{Y}|\,\boldsymbol{\theta}) = - \frac{1}{2} \left ( N \ln 2 \pi +  \sum_i^N \sigma_i^2 + \chi^2(\boldsymbol{Y}|\,\boldsymbol{\theta}) \right )
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[
\chi^2(\boldsymbol{Y}|\,\boldsymbol{\theta}) = \sum_i^N \frac{(Y_i - M(x |\,\boldsymbol{\theta}))^2}{\sigma_i^2}.
\]</div>
</section>
<section id="changes-for-complex-valued-fourier-data">
<h3>Changes for complex-valued Fourier data<a class="headerlink" href="#changes-for-complex-valued-fourier-data" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title">More bits</p>
<p>This is why both numpy and pytorch have a <code class="docutils literal notranslate"><span class="pre">complex128</span></code> data type, which stores real and imaginary components as <code class="docutils literal notranslate"><span class="pre">float64</span></code> values.</p>
</aside>
<p>The likelihood function for complex-valued Fourier data with Gaussian uncertainties follows the same pattern, but with a few modifications. A complex data point actually contains more information than a single real data point, since there two numbers (real and imaginary) instead of just one.</p>
<p>Thankfully, as we pointed out in the <a class="reference internal" href="../rml_intro.html"><span class="doc std std-doc">Introduction to RML Imaging</span></a>, the measurements of the real and imaginary components are independent. This simplifies life tremendously and means that we can write the joint likelihood function of the full complex-valued visibility dataset as the product of the likelihood function for the real visibilities and the likelihood function for the imaginary visibilities</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\boldsymbol{V} |\,\boldsymbol{\theta} ) = \mathcal{L}(\boldsymbol{V}_\mathrm{Re} |\,\boldsymbol{\theta} ) \mathcal{L}(\boldsymbol{V}_\mathrm{Im} |\,\boldsymbol{\theta} ).
\]</div>
<p>Within a given channel, Fourier data from sub-mm interferometric arrays like ALMA is well-characterized by independent Gaussian noise (the <a class="reference external" href="https://github.com/MPoL-dev/MPoL/issues/18">cross-channel situation</a> is another story). Therefore, we can follow the same simplifications as before to arrive at an expression for the log likelihood function of complex visibility data</p>
<aside class="margin sidebar">
<p class="sidebar-title">Full likelihood function</p>
<p>Note that this full form of <span class="math notranslate nohighlight">\(\ln \mathcal{L}(\boldsymbol{V} |\,\boldsymbol{\theta} )\)</span> is what you’ll want to use in any situation where you are doing parameter inference, care about the uncertainties on your parameters (e.g., an MCMC fit), and may adjust <span class="math notranslate nohighlight">\(\sigma_i\)</span> values.</p>
</aside>
<div class="math notranslate nohighlight">
\[
\ln \mathcal{L}(\boldsymbol{V} |\,\boldsymbol{\theta} ) = - \left ( N \ln 2 \pi +  \sum_i^N \sigma_i^2 + \frac{1}{2} \chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}) \right )
\]</div>
<p>Note than an extra factor of 2 appears in some places compared to the fully-real example. In this situation, the <span class="math notranslate nohighlight">\(\chi^2\)</span> is either directly evaluated with complex-valued data and model components as</p>
<div class="math notranslate nohighlight">
\[
\chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}) = \sum_i^N \frac{|V_i - M(u_i, v_i |\,\boldsymbol{\theta})|^2}{\sigma_i^2}
\]</div>
<p>or is split into separate <span class="math notranslate nohighlight">\(\chi^2\)</span> sums for the real and imaginary data</p>
<div class="math notranslate nohighlight">
\[
\chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}) = \sum_i^N \frac{(V_{\mathrm{Re},i} - M_\mathrm{Re}(u_i, v_i |\,\boldsymbol{\theta}))^2}{\sigma_i^2} + \sum_i^N \frac{(V_{\mathrm{Im},i} - M_\mathrm{Im}(u_i, v_i |\,\boldsymbol{\theta}))^2}{\sigma_i^2}.
\]</div>
<aside class="margin sidebar">
<p class="sidebar-title">Simplified likelihood function</p>
<p>You can use this form of <span class="math notranslate nohighlight">\(\ln \mathcal{L}(\boldsymbol{V} |\,\boldsymbol{\theta} )\)</span> in any situation where you are doing parameter inference, care about the uncertainties on your parameters (e.g., an MCMC fit), but are keeping <span class="math notranslate nohighlight">\(\sigma_i\)</span> values fixed.</p>
</aside>
<p>Many times, we will be working in situations where the <span class="math notranslate nohighlight">\(\sigma_i\)</span> values of the dataset are assumed to be constant. In these situations, we can further reduce the log likelihood function to a proportionality</p>
<div class="math notranslate nohighlight">
\[
\ln \mathcal{L}(\boldsymbol{V}|\,\boldsymbol{\theta}) \propto - \frac{1}{2} \chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}) .
\]</div>
<p>Though it’s common to talk about likelihood functions as “the probability of the data” given model parameters, especially in a Bayesian context, the overall normalization of the likelihood function on its own <a class="reference external" href="https://hea-www.harvard.edu/AstroStat/aas227_2016/lecture1_Robinson.pdf">is not defined</a>. This means that the value of the likelihood function (and component parts, like <span class="math notranslate nohighlight">\(\chi^2\)</span>) can and will be different if the dataset has been binned, even though we might be using exactly the same model. This isn’t a problem, though, because the important thing is that, regardless of normalization, the likelihood function will convey the same information (mean and uncertainty) about the model parameters, because this depends on the shape of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as a function of <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p>
<p>In a Bayesian context, the normalization of the posterior distribution is typically called the “Bayesian evidence.” In evaluating this evidence, any normalization constant for the likelihood function would cancel out (e.g., see Equations 10 &amp; 11 of <a class="reference external" href="https://arxiv.org/abs/1205.4446">Hogg 2011</a>).</p>
<p>Now we’ll evaluate the likelihood function using both the loose visibilities produced using the <a class="reference internal" href="../api.html#mpol.fourier.NuFFT" title="mpol.fourier.NuFFT"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.NuFFT</span></code></a> and the gridded visibilities produced using the <a class="reference internal" href="../api.html#mpol.fourier.FourierCube" title="mpol.fourier.FourierCube"><code class="xref py py-class docutils literal notranslate"><span class="pre">mpol.fourier.FourierCube</span></code></a>.</p>
</section>
<section id="loose-visibility-log-likelihood">
<h3>“Loose” visibility log likelihood<a class="headerlink" href="#loose-visibility-log-likelihood" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># convert data and weight to pytorch tensors for use in the calls</span>
<span class="n">data_loose</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">weight_loose</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>

<span class="n">chisquare</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">chi_squared</span><span class="p">(</span><span class="n">vis_model_loose</span><span class="p">,</span> <span class="n">data_loose</span><span class="p">,</span> <span class="n">weight_loose</span><span class="p">)</span>
<span class="n">loglike</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">vis_model_loose</span><span class="p">,</span> <span class="n">data_loose</span><span class="p">,</span> <span class="n">weight_loose</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Chi squared&quot;</span><span class="p">,</span> <span class="n">chisquare</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Log likelihood&quot;</span><span class="p">,</span> <span class="n">loglike</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Chi squared tensor(5847303.7855, dtype=torch.float64, grad_fn=&lt;SumBackward0&gt;)
Log likelihood tensor(14577405.9755, dtype=torch.float64, grad_fn=&lt;AddBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="gridded-visibility-log-likelihood">
<h3>Gridded visibility log likelihood<a class="headerlink" href="#gridded-visibility-log-likelihood" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chisquare_gridded</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">chi_squared_gridded</span><span class="p">(</span><span class="n">vis_model_gridded</span><span class="p">,</span> <span class="n">gridded_dset</span><span class="p">)</span>
<span class="n">loglike_gridded</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">log_likelihood_gridded</span><span class="p">(</span><span class="n">vis_model_gridded</span><span class="p">,</span> <span class="n">gridded_dset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Chi squared gridded&quot;</span><span class="p">,</span> <span class="n">chisquare_gridded</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Log likelihood gridded&quot;</span><span class="p">,</span> <span class="n">loglike_gridded</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Chi squared gridded tensor(53094.1556, dtype=torch.float64, grad_fn=&lt;SumBackward0&gt;)
Log likelihood gridded tensor(57464.8101, dtype=torch.float64, grad_fn=&lt;AddBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>As we just discussed, it’s OK that these evaluations are different between the loose and the gridded visibilities, even though we are using the exact same image plane model.</p>
</section>
</section>
<section id="normalized-negative-log-likelihood-loss-function">
<h2>Normalized negative log likelihood loss function<a class="headerlink" href="#normalized-negative-log-likelihood-loss-function" title="Permalink to this headline">#</a></h2>
<p>In an RML workflow, rather than talk about maximizing likelihood functions, we usually talk about minimizing loss functions. As described in the <a class="reference internal" href="../rml_intro.html"><span class="doc std std-doc">Introduction to RML Imaging</span></a>, we will usually compile a target loss function <span class="math notranslate nohighlight">\(L\)</span> as the sum of several individual loss functions: a (negative) log-likelihood loss function and several regularizers. If we are just optimizing <span class="math notranslate nohighlight">\(L\)</span>, we only care about the value of <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}\)</span> that minimizes the function <span class="math notranslate nohighlight">\(L\)</span>. The constant of proportionality does not matter, we only care that <span class="math notranslate nohighlight">\(L(\hat{\boldsymbol{\theta}}) &lt; L(\hat{\boldsymbol{\theta}} + \epsilon)\)</span>, not by how much.</p>
<p>In this application, the <em>relative proportionality</em> (strength) of each loss function or regularizer is important. If we use the log likelihood function discussed so far, then its absolute value will change significantly when we use more or less data. This means that in order to give similar relative regularization, the pre-factors of the other loss terms will also need to be changed in response. This makes it hard to translate ballpark regularizer strengths from one dataset to another.</p>
<aside class="margin sidebar">
<p class="sidebar-title">Wrong for uncertainties</p>
<p>N.B. that you do not use this normalized form of the likelihood function for any quantification of the uncertainty on your model parameters. Because it has the wrong proportionality, its relative dependence on <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> will be different and therefore yield incorrect parameter uncertainties.</p>
</aside>
<p>In these applications we recommend using a normalized negative log likelihood loss function of the form</p>
<div class="math notranslate nohighlight">
\[
L_\mathrm{nll} = \frac{1}{2 N} \sum_i^{N} \frac{|V_i - M(u_i, v_i |\,\boldsymbol{\theta})|^2}{\sigma_i^2} =  \frac{1}{2 N} \chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}),
\]</div>
<p>following <a class="reference external" href="https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract">EHT-IV 2019</a>. This formulation works because a “well-fit” model will have</p>
<div class="math notranslate nohighlight">
\[
V_i \approx M(u_i, v_i |\,\boldsymbol{\theta})
\]</div>
<p>but will be wrong on average by the amount of noise <span class="math notranslate nohighlight">\(\epsilon_i\)</span> present in <span class="math notranslate nohighlight">\(V_i\)</span>. Thus,</p>
<div class="math notranslate nohighlight">
\[
\langle |V_i - M(u_i, v_i |\,\boldsymbol{\theta})|^2 \rangle = \sigma_{\mathrm{Re},i}^2 + \sigma_{\mathrm{Im},i}^2 = 2 \sigma_i^2
\]</div>
<p>This is the same reasoning that gives rise to the statistical apothegm “a well-fit model has a reduced <span class="math notranslate nohighlight">\(\chi^2_R \approx 1\)</span>” (one that has <a class="reference external" href="https://arxiv.org/abs/1012.3754">many caveats and pitfalls</a>). In this case the extra factor of 2 in the denominator comes about because the visibility data and its noise are complex-valued.</p>
<p>The hope is that for many applications, the normalized negative log likelihood loss function will have a minimum value of <span class="math notranslate nohighlight">\(L(\hat{\boldsymbol{\theta}}) \approx 1\)</span> for a well-fit model (regardless of the number of data points), making it easier to set the regularizer strengths <em>relative</em> to this value. Note that even this normalized loss won’t be the same between an unbinned and binned dataset, though hopefully both will be on the order of <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>This loss function is implemented in <a class="reference internal" href="../api.html#mpol.losses.nll" title="mpol.losses.nll"><code class="xref py py-func docutils literal notranslate"><span class="pre">mpol.losses.nll()</span></code></a> and <a class="reference internal" href="../api.html#mpol.losses.nll_gridded" title="mpol.losses.nll_gridded"><code class="xref py py-func docutils literal notranslate"><span class="pre">mpol.losses.nll_gridded()</span></code></a>, and we can see the results here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nll</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">nll</span><span class="p">(</span><span class="n">vis_model_loose</span><span class="p">,</span> <span class="n">data_loose</span><span class="p">,</span> <span class="n">weight_loose</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalized log likelihood&quot;</span><span class="p">,</span> <span class="n">nll</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normalized log likelihood tensor(0.9993, dtype=torch.float64, grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nll_gridded</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">nll_gridded</span><span class="p">(</span><span class="n">vis_model_gridded</span><span class="p">,</span> <span class="n">gridded_dset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalized log likelihood gridded&quot;</span><span class="p">,</span> <span class="n">nll_gridded</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normalized log likelihood gridded tensor(1.6241, dtype=torch.float64, grad_fn=&lt;MulBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="optimization.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Intro to RML with MPoL</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="crossvalidation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Cross validation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ian Czekala<br/>
  
      &copy; Copyright 2019-22, Ian Czekala.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>