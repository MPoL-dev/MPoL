

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mpol.losses &mdash; MPoL 0.1.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://buttons.github.io/buttons.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/bullets.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/faculty.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans|Roboto:400,700|Roboto+Mono:400,700&display=swap" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

  
    <a class="heading heading-extra-margin" href="../../index.html">
      <div class="logo-box logo-box-large">
        <img class="logo" src="../../_static/logo.png"/>
      </div>
      
        <span class="icon icon-home"> MPoL</span>
      
    </a>
  

  
    
    
      <div class="version">0.1.1</div>
    
  

  
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rml_intro.html">Introduction to Regularized Maximum Likelihood Imaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">MPoL Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../units-and-conventions.html">Units and Conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer-documentation.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/PyTorch.html">Introduction to PyTorch: Tensors and Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/gridder.html">Gridding and diagnostic images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/optimization.html">Optimization Loop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/crossvalidation.html">Cross validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/gpu_setup.html">GPU Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/initializedirtyimage.html">Initializing with the Dirty Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../large-tutorials/HD143006_part_1.html">HD143006 Tutorial Part 1</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MPoL</a>
        
      </nav>


      <div class="wy-nav-content">

  

  
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
  <li class="breadcrumb"><a href="../../index.html">MPoL</a> &raquo;</li>
    
      <li class="breadcrumb"><a href="../index.html">Module code</a> &raquo;</li>
    
  <li class="breadcrumb">mpol.losses</li>

    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mpol.losses</h1><div class="highlight"><pre>
<span></span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The following loss functions are available to use in imaging. Many of the definitions follow those in Appendix A of `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_, including the regularization strength, which aspires to be similar across all terms, providing at least a starting point for tuning multiple loss functions.</span>

<span class="sd">If you don&#39;t see a loss function you need, it&#39;s easy to write your own directly within your optimization script. If you like it, please consider opening a pull request!</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">connectors</span>
<span class="kn">from</span> <span class="nn">.constants</span> <span class="kn">import</span> <span class="o">*</span>


<div class="viewcode-block" id="nll"><a class="viewcode-back" href="../../api.html#mpol.losses.nll">[docs]</a><span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">data_vis</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the weighted :math:`\chi^2` loss between data and model visibilities. Visibilities may be any shape as long as all</span>
<span class="sd">    quantities have the same shape. Following `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_, we apply</span>
<span class="sd">    the prefactor :math:`1/(2 N_V)`, where :math:`N_V` is the number of visibilities. The factor of 2 comes in because we must count real</span>
<span class="sd">    and imaginaries in the :math:`\chi^2` sum.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_vis (PyTorch complex): array tuple of the model</span>
<span class="sd">        data_vis (PyTorch complex): array of the data values</span>
<span class="sd">        weight (PyTorch real): array of weight values</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the :math:`\chi^2` likelihood loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \frac{1}{2 N_V}\left ( \sum_i w_i (D_{\Re, i} - M_{\Re, i})^2 + \sum_i w_i (D_{\Im, i} - M_{\Im, i})^2 \right)</span>

<span class="sd">    where :math:`w` are the visibility weights, :math:`D_\Re` and :math:`D_\Im` are the real and imaginary components of the data visibilities, respectively, and :math:`M_\Re` and :math:`M_\Im` are the real and imaginary components of the model visibilities, respectively.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nvis</span> <span class="o">=</span> <span class="n">data_vis</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># return 1 / (2 * nvis) * torch.sum(weight * torch.abs(data_vis - model_vis) ** 2)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="mi">1</span>
        <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">nvis</span><span class="p">)</span>
        <span class="o">*</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="p">(</span><span class="n">data_vis</span><span class="o">.</span><span class="n">real</span> <span class="o">-</span> <span class="n">model_vis</span><span class="o">.</span><span class="n">real</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="p">(</span><span class="n">data_vis</span><span class="o">.</span><span class="n">imag</span> <span class="o">-</span> <span class="n">model_vis</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="nll_gridded"><a class="viewcode-back" href="../../api.html#mpol.losses.nll_gridded">[docs]</a><span class="k">def</span> <span class="nf">nll_gridded</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">datasetGridded</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the weighted :math:`\chi^2` loss between gridded data and model visibilities. Visibilities may be any shape as long as all</span>
<span class="sd">    quantities have the *same* shape. Following `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_, we apply</span>
<span class="sd">    the prefactor :math:`1/(2 N_V)`, where :math:`N_V` is the number of visibilities. The factor of 2 comes in because we must count real</span>
<span class="sd">    and imaginaries in the :math:`\chi^2` sum.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_vis (PyTorch complex): array tuple of the model</span>
<span class="sd">        data_vis (PyTorch complex): array of the data values</span>
<span class="sd">        weight (PyTorch real): array of weight values</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the :math:`\chi^2` likelihood loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \frac{1}{2 N_V}\left ( \sum_i w_i (D_{\Re, i} - M_{\Re, i})^2 + \sum_i w_i (D_{\Im, i} - M_{\Im, i})^2 \right)</span>

<span class="sd">    where :math:`w` are the visibility weights, :math:`D_\Re` and :math:`D_\Im` are the real and imaginary components of the data visibilities, respectively, and :math:`M_\Re` and :math:`M_\Im` are the real and imaginary components of the model visibilities, respectively.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_vis</span> <span class="o">=</span> <span class="n">connectors</span><span class="o">.</span><span class="n">index_vis</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">datasetGridded</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nll</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">datasetGridded</span><span class="o">.</span><span class="n">vis_indexed</span><span class="p">,</span> <span class="n">datasetGridded</span><span class="o">.</span><span class="n">weight_indexed</span><span class="p">)</span></div>


<div class="viewcode-block" id="entropy"><a class="viewcode-back" href="../../api.html#mpol.losses.entropy">[docs]</a><span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">prior_intensity</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the entropy loss of a set of pixels following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (any tensor): pixel values must be positive :math:`I_i &gt; 0` for all :math:`i`</span>
<span class="sd">        prior_intensity (any tensor): the prior value :math:`p` to calculate entropy against. Could be a single constant or an array the same shape as image.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: entropy loss</span>

<span class="sd">    The entropy loss is calculated as</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \frac{1}{\sum_i I_i} \sum_i I_i \; \ln \frac{I_i}{p_i}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># check to make sure image is positive, otherwise raise an error</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">cube</span> <span class="o">&gt;=</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s2">&quot;image cube contained negative pixel values&quot;</span>
    <span class="k">assert</span> <span class="n">prior_intensity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;image prior intensity must be positive&quot;</span>

    <span class="n">tot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cube</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">tot</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cube</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cube</span> <span class="o">/</span> <span class="n">prior_intensity</span><span class="p">))</span></div>


<div class="viewcode-block" id="TV_image"><a class="viewcode-back" href="../../api.html#mpol.losses.TV_image">[docs]</a><span class="k">def</span> <span class="nf">TV_image</span><span class="p">(</span><span class="n">sky_cube</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the total variation (TV) loss in the image dimension (R.A. and DEC). Following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_ Promotes the image to be piecewise smooth and the gradient of the image to be sparse.</span>

<span class="sd">    Args:</span>
<span class="sd">        sky_cube (any 3D tensor): the image cube array :math:`I_{lmv}`, where :math:`l` is R.A. in :math:`ndim=3`, :math:`m` is DEC in :math:`ndim=2`, and :math:`v` is the channel (velocity or frequency) dimension in :math:`ndim=1`. Should be in sky format representation.</span>
<span class="sd">        epsilon (float): a softening parameter in [:math:`\mathrm{Jy}/\mathrm{arcsec}^2`]. Any pixel-to-pixel variations within each image slice greater than this parameter will have a significant penalty.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: total variation loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_{l,m,v} \sqrt{(I_{l + 1, m, v} - I_{l,m,v})^2 + (I_{l, m+1, v} - I_{l, m, v})^2 + \epsilon}</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># diff the cube in ll and remove the last row</span>
    <span class="n">diff_ll</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># diff the cube in mm and remove the last column</span>
    <span class="n">diff_mm</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_ll</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">diff_mm</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="TV_channel"><a class="viewcode-back" href="../../api.html#mpol.losses.TV_channel">[docs]</a><span class="k">def</span> <span class="nf">TV_channel</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the total variation (TV) loss in the channel dimension. Following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (any 3D tensor): the image cube array :math:`I_{lmv}`</span>
<span class="sd">        epsilon (float): a softening parameter in [:math:`\mathrm{Jy}/\mathrm{arcsec}^2`]. Any channel-to-channel pixel variations greater than this parameter will have a significant penalty.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: total variation loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_{l,m,v} \sqrt{(I_{l, m, v + 1} - I_{l,m,v})^2 + \epsilon}</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># calculate the difference between the n+1 cube and the n cube</span>
    <span class="n">diff_vel</span> <span class="o">=</span> <span class="n">cube</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">cube</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_vel</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="edge_clamp"><a class="viewcode-back" href="../../api.html#mpol.losses.edge_clamp">[docs]</a><span class="k">def</span> <span class="nf">edge_clamp</span><span class="p">(</span><span class="n">cube</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Promote all pixels at the edge of the image to be zero using an :math:`L_2` norm.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (any 3D tensor): the array and pixel values</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: edge loss</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># find edge pixels</span>
    <span class="c1"># all channels</span>
    <span class="c1"># pixel edges</span>
    <span class="n">bt_edges</span> <span class="o">=</span> <span class="n">cube</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">lr_edges</span> <span class="o">=</span> <span class="n">cube</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bt_edges</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lr_edges</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="sparsity"><a class="viewcode-back" href="../../api.html#mpol.losses.sparsity">[docs]</a><span class="k">def</span> <span class="nf">sparsity</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enforce a sparsity prior on the image cube using the :math:`L_1` norm. Optionally provide a boolean mask to apply the prior to only the ``True`` locations. For example, you might want this mask to be ``True`` for background regions.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (nchan, npix, npix): tensor image cube</span>
<span class="sd">        mask (boolean): tensor array the same shape as ``cube``. The sparsity prior will be applied to those pixels where the mask is ``True``. Default is to apply prior to all pixels.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: sparsity loss calculated where ``mask == True``</span>

<span class="sd">    The sparsity loss calculated as</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_i | I_i |</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cube</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cube</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="UV_sparsity"><a class="viewcode-back" href="../../api.html#mpol.losses.UV_sparsity">[docs]</a><span class="k">def</span> <span class="nf">UV_sparsity</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">q_max</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enforce a sparsity prior for all :math:`q = \sqrt{u^2 + v^2}` points larger than :math:`q_\mathrm{max}`.</span>

<span class="sd">    Args:</span>
<span class="sd">        vis (torch.double) : visibility cube of (nchan, npix, npix//2 +1, 2)</span>
<span class="sd">        qs: numpy array corresponding to visibility coordinates. Dimensionality of (npix, npix//2)</span>
<span class="sd">        q_max (float): maximum radial baseline</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: UV sparsity loss above :math:`q_\mathrm{max}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># make a mask, then send it to the device (in case we&#39;re using a GPU)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="n">qs</span> <span class="o">&gt;</span> <span class="n">q_max</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">vis</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">vis_re</span> <span class="o">=</span> <span class="n">vis</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">vis_im</span> <span class="o">=</span> <span class="n">vis</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># broadcast mask to the same shape as vis</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vis_re</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vis_im</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="PSD"><a class="viewcode-back" href="../../api.html#mpol.losses.PSD">[docs]</a><span class="k">def</span> <span class="nf">PSD</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">psd</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a loss function corresponding to the power spectral density using a Gaussian process kernel.</span>

<span class="sd">    Assumes an image plane kernel of</span>

<span class="sd">    .. math::</span>

<span class="sd">        k(r) = exp(-\frac{r^2}{2 \ell^2})</span>

<span class="sd">    The corresponding power spectral density is</span>

<span class="sd">    .. math::</span>

<span class="sd">        P(q) = (2 \pi \ell^2) exp(- 2 \pi^2 \ell^2 q^2)</span>


<span class="sd">    Args:</span>
<span class="sd">        qs (torch.double): the radial UV coordinate (in kilolambda)</span>
<span class="sd">        psd (torch.double): the power spectral density cube</span>
<span class="sd">        l (torch.double): the correlation length in the image plane (in arcsec)</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double : the loss calculated using the power spectral density</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># stack to the full 3D shape</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">qs</span> <span class="o">*</span> <span class="mf">1e3</span>  <span class="c1"># lambda</span>

    <span class="n">l_rad</span> <span class="o">=</span> <span class="n">l</span> <span class="o">*</span> <span class="n">arcsec</span>  <span class="c1"># radians</span>

    <span class="c1"># calculate the expected power spectral density</span>
    <span class="n">expected_PSD</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">l_rad</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">l_rad</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">qs</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># evaluate the chi^2 for the PSD, making sure it broadcasts across all channels</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">psd</span> <span class="o">/</span> <span class="n">expected_PSD</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="TSV"><a class="viewcode-back" href="../../api.html#mpol.losses.TSV">[docs]</a><span class="k">def</span> <span class="nf">TSV</span><span class="p">(</span><span class="n">sky_cube</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the total square variation (TSV) loss in the image dimension (R.A. and DEC). Following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_ Promotes the image to be edge smoothed which may be a better reoresentation of the truth image `K. Kuramochi et al 2018 &lt;https://ui.adsabs.harvard.edu/abs/2018ApJ...858...56K/abstract&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        sky_cube (any 3D tensor): the image cube array :math:`I_{lmv}`, where :math:`l` is R.A. in :math:`ndim=3`, :math:`m` is DEC in :math:`ndim=2`, and :math:`v` is the channel (velocity or frequency) dimension in :math:`ndim=1`. Should be in sky format representation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: total square variation loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_{l,m,v} (I_{l + 1, m, v} - I_{l,m,v})^2 + (I_{l, m+1, v} - I_{l, m, v})^2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># diff the cube in ll and remove the last row</span>
    <span class="n">diff_ll</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># diff the cube in mm and remove the last column</span>
    <span class="n">diff_mm</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff_ll</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">diff_mm</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-21, Ian Czekala

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>


      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-5472810-8', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>