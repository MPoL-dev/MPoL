

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>mpol.losses &#8212; MPoL 0.2.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="https://buttons.github.io/buttons.js"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/mpol/losses';</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="MPoL 0.2.0 documentation - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="MPoL 0.2.0 documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rml_intro.html">Introduction to Regularized Maximum Likelihood Imaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">MPoL Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../units-and-conventions.html">Units and Conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer-documentation.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/PyTorch.html">Introduction to PyTorch: Tensors and Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/gridder.html">Gridding and diagnostic images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/optimization.html">Intro to RML with MPoL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/loose-visibilities.html">Likelihood functions and model visibilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/crossvalidation.html">Cross validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/gpu_setup.html">GPU Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/initializedirtyimage.html">Initializing with the Dirty Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../large-tutorials/HD143006_part_1.html">HD143006 Tutorial Part 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../large-tutorials/HD143006_part_2.html">HD143006 Tutorial Part 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci-tutorials/fakedata.html">Making a Mock Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../large-tutorials/pyro.html">Parametric Inference with Pyro</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/MPoL-dev/MPoL" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for mpol.losses</h1><div class="highlight"><pre>
<span></span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The following loss functions are available to use in imaging. Many of the definitions follow those in Appendix A of `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_, including the regularization strength, which aspires to be similar across all terms, providing at least a starting point for tuning multiple loss functions.</span>

<span class="sd">If you don&#39;t see a loss function you need, it&#39;s easy to write your own directly within your optimization script. If you like it, please consider opening a pull request!</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">.constants</span> <span class="kn">import</span> <span class="o">*</span>


<div class="viewcode-block" id="chi_squared"><a class="viewcode-back" href="../../api.html#mpol.losses.chi_squared">[docs]</a><span class="k">def</span> <span class="nf">chi_squared</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">data_vis</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the :math:`\chi^2` between the complex data :math:`\boldsymbol{V}` and model :math:`M` visibilities using</span>

<span class="sd">    .. math::</span>

<span class="sd">        \chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}) = \sum_i^N \frac{|V_i - M(u_i, v_i |\,\boldsymbol{\theta})|^2}{\sigma_i^2}</span>

<span class="sd">    where :math:`\sigma_i^2 = 1/w_i`. The sum is over all of the provided visibilities. This function is agnostic as to whether the sum should include the Hermitian conjugate visibilities, but be aware that the answer returned will be different between the two cases. We recommend not including the Hermitian conjugates.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_vis (PyTorch complex): array tuple of the model representing :math:`\boldsymbol{V}`</span>
<span class="sd">        data_vis (PyTorch complex): array of the data values representing :math:`M`</span>
<span class="sd">        weight (PyTorch real): array of weight values representing :math:`w_i`</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the :math:`\chi^2` likelihood</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># print(&quot;inside chi_squared&quot;)</span>
    <span class="c1"># print(&quot;model&quot;, model_vis.shape)</span>
    <span class="c1"># print(&quot;data&quot;, data_vis.shape)</span>
    <span class="c1"># print(&quot;weight&quot;, weight.shape)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_vis</span> <span class="o">-</span> <span class="n">model_vis</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span></div>


<div class="viewcode-block" id="log_likelihood"><a class="viewcode-back" href="../../api.html#mpol.losses.log_likelihood">[docs]</a><span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">data_vis</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the log likelihood function :math:`\ln\mathcal{L}` between the complex data :math:`\boldsymbol{V}` and model :math:`M` visibilities using</span>

<span class="sd">    .. math::</span>

<span class="sd">        \ln \mathcal{L}(\boldsymbol{V}|\,\boldsymbol{\theta}) = - \left ( N \ln 2 \pi +  \sum_i^N \sigma_i^2 + \frac{1}{2} \chi^2(\boldsymbol{V}|\,\boldsymbol{\theta}) \right )</span>

<span class="sd">    where :math:`\chi^2` is evaluated using :func:`mpol.losses.chi_squared`.</span>

<span class="sd">    This function is agnostic as to whether the sum should include the Hermitian conjugate visibilities, but be aware that the normalization of the answer returned will be different between the two cases. Inference of the parameter values should be unaffected. We recommend not including the Hermitian conjugates.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_vis (PyTorch complex): array tuple of the model representing :math:`\boldsymbol{V}`</span>
<span class="sd">        data_vis (PyTorch complex): array of the data values representing :math:`M`</span>
<span class="sd">        weight (PyTorch real): array of weight values representing :math:`w_i`</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the :math:`\ln\mathcal{L}` log likelihood</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># If model and data are multidimensional, then flatten them to get full N</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">data_vis</span><span class="p">))</span>

    <span class="n">sigma_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">weight</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">N</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
        <span class="o">+</span> <span class="n">sigma_term</span>
        <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">chi_squared</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">data_vis</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="nll"><a class="viewcode-back" href="../../api.html#mpol.losses.nll">[docs]</a><span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">data_vis</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate a normalized &quot;negative log likelihood&quot; loss between the complex data :math:`\boldsymbol{V}` and model :math:`M` visibilities using</span>

<span class="sd">    .. math::</span>

<span class="sd">        L_\mathrm{nll} = \frac{1}{2 N} \chi^2(\boldsymbol{V}|\,\boldsymbol{\theta})</span>

<span class="sd">    where :math:`\chi^2` is evaluated using :func:`mpol.losses.chi_squared`. Visibilities may be any shape as long as all quantities have the same shape. Following `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_, we apply</span>
<span class="sd">    a prefactor :math:`1/(2 N)`, where :math:`N` is the number of visibilities. The factor of 2 comes in because we must count real and imaginaries in the :math:`\chi^2` sum. This means that this normalized negative log likelihood loss function will have a minimum value of $L_\mathrm{nll}(\hat{\boldsymbol{\theta}}) \approx 1$ for a well-fit model (regardless of the number of data points), making it easier to set the prefactor strengths of other regularizers *relative* to this value.</span>

<span class="sd">    Note that this function should only be used in an optimization or point estimate situation. If it is used in any situation where uncertainties on parameter values are determined (such as Markov Chain Monte Carlo), it will return the wrong answer. This is because the relative scaling of :math:`L_\mathrm{nll}` with respect to parameter value is incorrect.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_vis (PyTorch complex): array tuple of the model representing :math:`\boldsymbol{V}`</span>
<span class="sd">        data_vis (PyTorch complex): array of the data values representing :math:`M`</span>
<span class="sd">        weight (PyTorch real): array of weight values representing :math:`w_i`</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the normalized negative log likelihood likelihood loss</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># If model and data are multidimensional, then flatten them to get full N</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">data_vis</span><span class="p">))</span>

    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">chi_squared</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">data_vis</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span></div>


<div class="viewcode-block" id="chi_squared_gridded"><a class="viewcode-back" href="../../api.html#mpol.losses.chi_squared_gridded">[docs]</a><span class="k">def</span> <span class="nf">chi_squared_gridded</span><span class="p">(</span><span class="n">modelVisibilityCube</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the :math:`\chi^2` (corresponding to :func:`~mpol.losses.chi_squared`) using gridded data and model visibilities.</span>

<span class="sd">    Args:</span>
<span class="sd">        modelVisibilityCube (torch complex tensor): torch tensor with shape ``(nchan, npix, npix)`` to be indexed by the ``mask`` from :class:`~mpol.datasets.GriddedDataset`. Assumes tensor is &quot;pre-packed,&quot; as in output from :meth:`mpol.fourier.FourierCube.forward()`.</span>
<span class="sd">        griddedDataset: instantiated :class:`~mpol.datasets.GriddedDataset` object</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the :math:`\chi^2` value</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># get the model_visibilities from the dataset</span>
    <span class="c1"># 1D torch tensor collapsed across cube dimensions, like</span>
    <span class="c1"># griddedDataset.vis_indexed and griddedDataset.weight_indexed</span>
    
    <span class="n">model_vis</span> <span class="o">=</span> <span class="n">griddedDataset</span><span class="p">(</span><span class="n">modelVisibilityCube</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">chi_squared</span><span class="p">(</span>
        <span class="n">model_vis</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="o">.</span><span class="n">vis_indexed</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="o">.</span><span class="n">weight_indexed</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="log_likelihood_gridded"><a class="viewcode-back" href="../../api.html#mpol.losses.log_likelihood_gridded">[docs]</a><span class="k">def</span> <span class="nf">log_likelihood_gridded</span><span class="p">(</span><span class="n">modelVisibilityCube</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the log likelihood function :math:`\ln\mathcal{L}` (corresponding to :func:`~mpol.losses.log_likelihood`) using gridded data and model visibilities.</span>

<span class="sd">    Args:</span>
<span class="sd">        modelVisibilityCube (torch complex tensor): torch tensor with shape ``(nchan, npix, npix)`` to be indexed by the ``mask`` from :class:`~mpol.datasets.GriddedDataset`. Assumes tensor is &quot;pre-packed,&quot; as in output from :meth:`mpol.fourier.FourierCube.forward()`.</span>
<span class="sd">        griddedDataset: instantiated :class:`~mpol.datasets.GriddedDataset` object</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the :math:`\ln\mathcal{L}` value</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># get the model_visibilities from the dataset</span>
    <span class="c1"># 1D torch tensor collapsed across cube dimensions, like</span>
    <span class="c1"># griddedDataset.vis_indexed and griddedDataset.weight_indexed</span>
    <span class="n">model_vis</span> <span class="o">=</span> <span class="n">griddedDataset</span><span class="p">(</span><span class="n">modelVisibilityCube</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">log_likelihood</span><span class="p">(</span>
        <span class="n">model_vis</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="o">.</span><span class="n">vis_indexed</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="o">.</span><span class="n">weight_indexed</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="nll_gridded"><a class="viewcode-back" href="../../api.html#mpol.losses.nll_gridded">[docs]</a><span class="k">def</span> <span class="nf">nll_gridded</span><span class="p">(</span><span class="n">modelVisibilityCube</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate a normalized &quot;negative log likelihood&quot; (corresponding to :func:`~mpol.losses.nll`) using gridded data and model visibilities. Function will return the same value regardless of whether Hermitian pairs are included.</span>

<span class="sd">    Args:</span>
<span class="sd">        vis (torch complex tensor): torch tensor with shape ``(nchan, npix, npix)`` to be indexed by the ``mask`` from :class:`~mpol.datasets.GriddedDataset`. Assumes tensor is &quot;pre-packed,&quot; as in output from :meth:`mpol.fourier.FourierCube.forward()`.</span>
<span class="sd">        griddedDataset: instantiated :class:`~mpol.datasets.GriddedDataset` object</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: the normalized negative log likelihood likelihood loss</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_vis</span> <span class="o">=</span> <span class="n">griddedDataset</span><span class="p">(</span><span class="n">modelVisibilityCube</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nll</span><span class="p">(</span><span class="n">model_vis</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="o">.</span><span class="n">vis_indexed</span><span class="p">,</span> <span class="n">griddedDataset</span><span class="o">.</span><span class="n">weight_indexed</span><span class="p">)</span></div>


<div class="viewcode-block" id="entropy"><a class="viewcode-back" href="../../api.html#mpol.losses.entropy">[docs]</a><span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">prior_intensity</span><span class="p">,</span> <span class="n">tot_flux</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the entropy loss of a set of pixels following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (any tensor): pixel values must be positive :math:`I_i &gt; 0` for all :math:`i`</span>
<span class="sd">        prior_intensity (any tensor): the prior value :math:`p` to calculate entropy against. Could be a single constant or an array the same shape as image.</span>
<span class="sd">        tot_flux (float): a fixed normalization factor; the user-defined target total flux density</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: entropy loss</span>

<span class="sd">    The entropy loss is calculated as</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \frac{1}{\zeta} \sum_i I_i \; \ln \frac{I_i}{p_i}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># check to make sure image is positive, otherwise raise an error</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">cube</span> <span class="o">&gt;=</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s2">&quot;image cube contained negative pixel values&quot;</span>
    <span class="k">assert</span> <span class="n">prior_intensity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;image prior intensity must be positive&quot;</span>
    <span class="k">assert</span> <span class="n">tot_flux</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;target total flux must be positive&quot;</span>

    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">tot_flux</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cube</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cube</span> <span class="o">/</span> <span class="n">prior_intensity</span><span class="p">))</span></div>


<div class="viewcode-block" id="TV_image"><a class="viewcode-back" href="../../api.html#mpol.losses.TV_image">[docs]</a><span class="k">def</span> <span class="nf">TV_image</span><span class="p">(</span><span class="n">sky_cube</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the total variation (TV) loss in the image dimension (R.A. and DEC). Following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_ Promotes the image to be piecewise smooth and the gradient of the image to be sparse.</span>

<span class="sd">    Args:</span>
<span class="sd">        sky_cube (any 3D tensor): the image cube array :math:`I_{lmv}`, where :math:`l` is R.A. in :math:`ndim=3`, :math:`m` is DEC in :math:`ndim=2`, and :math:`v` is the channel (velocity or frequency) dimension in :math:`ndim=1`. Should be in sky format representation.</span>
<span class="sd">        epsilon (float): a softening parameter in [:math:`\mathrm{Jy}/\mathrm{arcsec}^2`]. Any pixel-to-pixel variations within each image slice greater than this parameter will have a significant penalty.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: total variation loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_{l,m,v} \sqrt{(I_{l + 1, m, v} - I_{l,m,v})^2 + (I_{l, m+1, v} - I_{l, m, v})^2 + \epsilon}</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># diff the cube in ll and remove the last row</span>
    <span class="n">diff_ll</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># diff the cube in mm and remove the last column</span>
    <span class="n">diff_mm</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_ll</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">diff_mm</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="TV_channel"><a class="viewcode-back" href="../../api.html#mpol.losses.TV_channel">[docs]</a><span class="k">def</span> <span class="nf">TV_channel</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the total variation (TV) loss in the channel dimension. Following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (any 3D tensor): the image cube array :math:`I_{lmv}`</span>
<span class="sd">        epsilon (float): a softening parameter in [:math:`\mathrm{Jy}/\mathrm{arcsec}^2`]. Any channel-to-channel pixel variations greater than this parameter will have a significant penalty.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: total variation loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_{l,m,v} \sqrt{(I_{l, m, v + 1} - I_{l,m,v})^2 + \epsilon}</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># calculate the difference between the n+1 cube and the n cube</span>
    <span class="n">diff_vel</span> <span class="o">=</span> <span class="n">cube</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">cube</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_vel</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="edge_clamp"><a class="viewcode-back" href="../../api.html#mpol.losses.edge_clamp">[docs]</a><span class="k">def</span> <span class="nf">edge_clamp</span><span class="p">(</span><span class="n">cube</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Promote all pixels at the edge of the image to be zero using an :math:`L_2` norm.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (any 3D tensor): the array and pixel values</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: edge loss</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># find edge pixels</span>
    <span class="c1"># all channels</span>
    <span class="c1"># pixel edges</span>
    <span class="n">bt_edges</span> <span class="o">=</span> <span class="n">cube</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">lr_edges</span> <span class="o">=</span> <span class="n">cube</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bt_edges</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lr_edges</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="sparsity"><a class="viewcode-back" href="../../api.html#mpol.losses.sparsity">[docs]</a><span class="k">def</span> <span class="nf">sparsity</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enforce a sparsity prior on the image cube using the :math:`L_1` norm. Optionally provide a boolean mask to apply the prior to only the ``True`` locations. For example, you might want this mask to be ``True`` for background regions.</span>

<span class="sd">    Args:</span>
<span class="sd">        cube (nchan, npix, npix): tensor image cube</span>
<span class="sd">        mask (boolean): tensor array the same shape as ``cube``. The sparsity prior will be applied to those pixels where the mask is ``True``. Default is to apply prior to all pixels.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: sparsity loss calculated where ``mask == True``</span>

<span class="sd">    The sparsity loss calculated as</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_i | I_i |</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cube</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cube</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="UV_sparsity"><a class="viewcode-back" href="../../api.html#mpol.losses.UV_sparsity">[docs]</a><span class="k">def</span> <span class="nf">UV_sparsity</span><span class="p">(</span><span class="n">vis</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">q_max</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enforce a sparsity prior for all :math:`q = \sqrt{u^2 + v^2}` points larger than :math:`q_\mathrm{max}`.</span>

<span class="sd">    Args:</span>
<span class="sd">        vis (torch.double) : visibility cube of (nchan, npix, npix//2 +1, 2)</span>
<span class="sd">        qs: numpy array corresponding to visibility coordinates. Dimensionality of (npix, npix//2)</span>
<span class="sd">        q_max (float): maximum radial baseline</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: UV sparsity loss above :math:`q_\mathrm{max}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># make a mask, then send it to the device (in case we&#39;re using a GPU)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="n">qs</span> <span class="o">&gt;</span> <span class="n">q_max</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">vis</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">vis_re</span> <span class="o">=</span> <span class="n">vis</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">vis_im</span> <span class="o">=</span> <span class="n">vis</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># broadcast mask to the same shape as vis</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vis_re</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vis_im</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="PSD"><a class="viewcode-back" href="../../api.html#mpol.losses.PSD">[docs]</a><span class="k">def</span> <span class="nf">PSD</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">psd</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a loss function corresponding to the power spectral density using a Gaussian process kernel.</span>

<span class="sd">    Assumes an image plane kernel of</span>

<span class="sd">    .. math::</span>

<span class="sd">        k(r) = exp(-\frac{r^2}{2 \ell^2})</span>

<span class="sd">    The corresponding power spectral density is</span>

<span class="sd">    .. math::</span>

<span class="sd">        P(q) = (2 \pi \ell^2) exp(- 2 \pi^2 \ell^2 q^2)</span>


<span class="sd">    Args:</span>
<span class="sd">        qs (torch.double): the radial UV coordinate (in kilolambda)</span>
<span class="sd">        psd (torch.double): the power spectral density cube</span>
<span class="sd">        l (torch.double): the correlation length in the image plane (in arcsec)</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double : the loss calculated using the power spectral density</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># stack to the full 3D shape</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">qs</span> <span class="o">*</span> <span class="mf">1e3</span>  <span class="c1"># lambda</span>

    <span class="n">l_rad</span> <span class="o">=</span> <span class="n">l</span> <span class="o">*</span> <span class="n">arcsec</span>  <span class="c1"># radians</span>

    <span class="c1"># calculate the expected power spectral density</span>
    <span class="n">expected_PSD</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">l_rad</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">l_rad</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">qs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># evaluate the chi^2 for the PSD, making sure it broadcasts across all channels</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">psd</span> <span class="o">/</span> <span class="n">expected_PSD</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="TSV"><a class="viewcode-back" href="../../api.html#mpol.losses.TSV">[docs]</a><span class="k">def</span> <span class="nf">TSV</span><span class="p">(</span><span class="n">sky_cube</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the total square variation (TSV) loss in the image dimension (R.A. and DEC). Following the definition in `EHT-IV 2019 &lt;https://ui.adsabs.harvard.edu/abs/2019ApJ...875L...4E/abstract&gt;`_ Promotes the image to be edge smoothed which may be a better reoresentation of the truth image `K. Kuramochi et al 2018 &lt;https://ui.adsabs.harvard.edu/abs/2018ApJ...858...56K/abstract&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        sky_cube (any 3D tensor): the image cube array :math:`I_{lmv}`, where :math:`l` is R.A. in :math:`ndim=3`, :math:`m` is DEC in :math:`ndim=2`, and :math:`v` is the channel (velocity or frequency) dimension in :math:`ndim=1`. Should be in sky format representation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.double: total square variation loss</span>

<span class="sd">    .. math::</span>

<span class="sd">        L = \sum_{l,m,v} (I_{l + 1, m, v} - I_{l,m,v})^2 + (I_{l, m+1, v} - I_{l, m, v})^2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># diff the cube in ll and remove the last row</span>
    <span class="n">diff_ll</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># diff the cube in mm and remove the last column</span>
    <span class="n">diff_mm</span> <span class="o">=</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sky_cube</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff_ll</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">diff_mm</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span></div>
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ian Czekala
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2019-22, Ian Czekala.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>